{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stable-baselines_1_getting_started.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/stable-baselines/blob/main/stable_baselines_1_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines Tutorial - Getting Started\n",
        "\n",
        "Github repo: https://github.com/araffin/rl-tutorial-jnrr19\n",
        "\n",
        "Stable-Baselines: https://github.com/hill-a/stable-baselines\n",
        "\n",
        "Documentation: https://stable-baselines.readthedocs.io/en/master/\n",
        "\n",
        "RL Baselines zoo: https://github.com/araffin/rl-baselines-zoo\n",
        "\n",
        "Medium article: [https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82](https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82)\n",
        "\n",
        "[RL Baselines Zoo](https://github.com/araffin/rl-baselines-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the basics for using stable baselines library: how to create a RL model, train it and evaluate it. Because all algorithms share the same interface, we will see how simple it is to switch from one algorithm to another.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/hill-a/stable-baselines).\n",
        "\n",
        "```\n",
        "sudo apt-get update && sudo apt-get install cmake libopenmpi-dev zlib1g-dev\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines[mpi]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWskDE2c9WoN",
        "outputId": "b8b71492-ee38-45ff-9ec7-97ce8e3f5be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines[mpi]==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "Requirement already satisfied: stable-baselines[mpi]==2.10.0 in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.2)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcX8hEcaUpR0"
      },
      "source": [
        "Stable-Baselines works on environments that follow the [gym interface](https://stable-baselines.readthedocs.io/en/master/guide/custom_env.html).\n",
        "You can find a list of available environment [here](https://gym.openai.com/envs/#classic_control).\n",
        "\n",
        "It is also recommended to check the [source code](https://github.com/openai/gym) to learn more about the observation and action space of each env, as gym does not have a proper documentation.\n",
        "Not all algorithms can work with all action spaces, you can find more in this [recap table](https://stable-baselines.readthedocs.io/en/master/guide/algos.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nhsIqzz33JK"
      },
      "source": [
        "##### recap table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPsty8dR3xgJ"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem\n",
        "\n",
        "- 첫번째로 해야 할 일은 RL model을 불러오는 것.\n",
        "- 어떤 문제에 무엇을 사용할 수 있는 지 알기 위해 documentation을 확인할 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7tKaBFrTR0a",
        "outputId": "c38708c8-79d7-4f1b-dabf-8c9e846e60c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "from stable_baselines import PPO2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0_8OQbOTTNT"
      },
      "source": [
        "The next thing you need to import is the policy class that will be used to create the networks (for the policy/value functions).\n",
        "This step is optional as you can directly use strings in the constructor: \n",
        "\n",
        "```PPO2('MlpPolicy', env)``` instead of ```PPO2(MlpPolicy, env)```\n",
        "\n",
        "Note that some algorithms like `SAC` have their own `MlpPolicy` (different from `stable_baselines.common.policies.MlpPolicy`), that's why using string for the policy is the recommened option.\n",
        "\n",
        "- 다음으로 가져와야하는 것은 네트워크를 만드는 데 사용할 policy class (policy/value functions을 위한).\n",
        "- 생성자(constructor)에서 문자열(strings)을 직접 사용할 수 있으므로, 이 단계는 선택 사항\n",
        "  - ```PPO2 (MlpPolicy, env)```대신```PPO2 ( 'MlpPolicy', env)```\n",
        "\n",
        "- `SAC`와 같은 일부 알고리즘에는 자체`MlpPolicy` (`stable_baselines.common.policies.MlpPolicy`와 다름)가 있으므로 policy를 위해 문자열을 사용하는 것이 권장되는 옵션임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROUJr675TT01"
      },
      "source": [
        "from stable_baselines.common.policies import MlpPolicy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will use CartPole environment, a classic control problem.\n",
        "\n",
        "\"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. \"\n",
        "\n",
        "Cartpole environment: [https://gym.openai.com/envs/CartPole-v1/](https://gym.openai.com/envs/CartPole-v1/)\n",
        "\n",
        "![Cartpole](https://cdn-images-1.medium.com/max/1143/1*h4WTQNVIsvMXJTCpXm_TAw.gif)\n",
        "\n",
        "\n",
        "We chose the MlpPolicy because the observation of the CartPole task is a feature vector, not images.\n",
        "- CartPole task의 observation은 이미지가 아닌 feature vector이기 때문에 MlpPolicy 선택\n",
        "\n",
        "The type of action to use (discrete/continuous) will be automatically deduced from the environment action space\n",
        "- action으로 discrete/continuous중 무엇을 사용할 지는 environment action space로 부터 자동으로 추론됨\n",
        "\n",
        "Here we are using the [Proximal Policy Optimization](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html) algorithm (PPO2 is the version optimized for GPU), which is an Actor-Critic method: it uses a value function to improve the policy gradient descent (by reducing the variance).\n",
        "- 여기에서 GPU에 최적화된 PPO2 알고리즘을 이용\n",
        "- PPO2는 Actor-Critic 방법으로 policy gradient descent를 개선하기 위해 Value function을 이용함\n",
        "\n",
        "It combines ideas from [A2C](https://stable-baselines.readthedocs.io/en/master/modules/a2c.html) (having multiple workers and using an entropy bonus for exploration) and [TRPO](https://stable-baselines.readthedocs.io/en/master/modules/trpo.html) (it uses a trust region to improve stability and avoid catastrophic drops in performance).\n",
        "- 이것은 A2C와 TRPO의 아이디어를 조합한 방법\n",
        "  - A2C는 exploration을 위해 multiple worker를 가지고, entropy bonus를 이용함\n",
        "  - TRPO는 stability를 개선하기 위해 trust region을 이용하고, 성능면에서 catastrophc drops을 피함\n",
        "\n",
        "PPO is an on-policy algorithm, which means that the trajectories used to update the networks must be collected using the latest policy.\n",
        "It is usually less sample efficient than off-policy alorithms like [DQN](https://stable-baselines.readthedocs.io/en/master/modules/dqn.html), [SAC](https://stable-baselines.readthedocs.io/en/master/modules/sac.html) or [TD3](https://stable-baselines.readthedocs.io/en/master/modules/td3.html), but is much faster regarding wall-clock time.\n",
        "- PPO는 on-policy 알고리즘임\n",
        "  - 즉, 네트워크들을 업데이트하기 위해 사용되는 trajectory들이 최신 policy를 사용하여 수집됨\n",
        "- DQN, SAC, TD3같은 off-policy알고리즘들보다는 sample efficiecy가 떨어지지만, 수행시간 관점에서 더 빠름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWGZp3i9wyf",
        "outputId": "f9356e37-5323-4630-dabb-53b52b6818e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = PPO2(MlpPolicy, env, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl"
      },
      "source": [
        "We create a helper function to evaluate the agent:\n",
        "- agent를 평가하는 helper 함수를 선언함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63M8mSKR-6Zt"
      },
      "source": [
        "def evaluate(model, num_episodes=100):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param model: (BaseRLModel object) the RL Agent\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    # This function will only work for a single Environment\n",
        "    # single Environment에 대해서만 작동함\n",
        "    env = model.get_env() \n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset() # e.g. [[ 0.04632042, -0.01863058, -0.03169358,  0.00881829]])\n",
        "        while not done:\n",
        "            # _states are only useful when using LSTM policies\n",
        "            action, _states = model.predict(obs) # e.g.: [0], None\n",
        "            # here, action, rewards and dones are arrays\n",
        "            # because we are using vectorized env\n",
        "            obs, reward, done, info = env.step(action) #e.g.: [[0.04, -0.24, -0.03, 0.27]], [1.0], [False], [{}]\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThk3Pf9CU1b"
      },
      "source": [
        "##### evaluat 함수 코드 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvLyskiyAZ2B",
        "outputId": "b0b33d0f-a2ec-43f9-bf47-5c77bad7d835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#YJ\n",
        "env.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04632042, -0.01863058, -0.03169358,  0.00881829]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_rR98I6BB2I",
        "outputId": "cb32ffe6-0ff1-421c-e3e5-10ef42742c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#YJ\n",
        "model.predict(env.reset())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0]), None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAk076JBQ3V",
        "outputId": "2c0a43eb-25c6-45ae-8bbd-dcd665910450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#YJ\n",
        "env.step(model.predict(env.reset())[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.0434584 , -0.24000068, -0.03723486,  0.27221394]],\n",
              "       dtype=float32), array([1.], dtype=float32), array([False]), [{}])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0-Y6jDbCZxS"
      },
      "source": [
        "##### original code 복귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEVOIY8NVeK"
      },
      "source": [
        "Let's evaluate the un-trained agent, this should be a random agent.\n",
        "- 학습되지 않은 agent 평가해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHLMA6NFk95",
        "outputId": "59a5b096-6116-4393-df36-4b09053d900d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Random Agent, before training\n",
        "mean_reward_before_train = evaluate(model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 22.66 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjjPxrwkYJ2i"
      },
      "source": [
        "Stable-Baselines already provides you with that helper:\n",
        "- Satble-Baselines는 이미 해당 helper를 가지고 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z6K9YImYJEx"
      },
      "source": [
        "from stable_baselines.common.evaluation import evaluate_policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oPTHjxyZSOL",
        "outputId": "d6f9eea2-17ac-4dd0-a4fa-66bd432a9d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train the agent and evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4cfSXIB-pTF",
        "outputId": "042377f9-fc3d-46bc-80bb-535bc7f6ec75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Train the agent for 10000 steps\n",
        "model.learn(total_timesteps=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.ppo2.ppo2.PPO2 at 0x7feeb33b24e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygl_gVmV_QP7",
        "outputId": "96372f2a-90a5-4867-f37f-6ee3c1e6a173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward:428.41 +/- 77.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNVol7oVD09l",
        "outputId": "33f8d4ef-8e34-484c-bab5-e1f7f0238bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "# Trained Agent, After training\n",
        "mean_reward_before_train = evaluate(model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 126.21 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00W6yY3NkHG"
      },
      "source": [
        "Apparently the training went well, the mean reward increased a lot ! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_o4lXsENvA"
      },
      "source": [
        "**새로 정의한 evaluate 함수와 내포된 evaluate_policy 결과가 너무 다름!!!  나중에 seed 고정하고 비교해보아야 함**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "We will record a video using the [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder) wrapper, you will learn about those wrapper in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOObbeu5MMlR"
      },
      "source": [
        "### Visualize trained agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iATu7AiyMQW2"
      },
      "source": [
        "record_video('CartPole-v1', model, video_length=500, prefix='ppo2-cartpole')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4i-fW3NojZ"
      },
      "source": [
        "show_videos('videos', prefix='ppo2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y8zg4V566qD"
      },
      "source": [
        "## Bonus: Train a RL Model in One Line\n",
        "\n",
        "The policy class to use will be inferred and the environment will be automatically created. This works because both are [registered](https://stable-baselines.readthedocs.io/en/master/guide/quickstart.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaOPfOrwWEP4",
        "outputId": "02087b97-2a10-4a89-a379-b446a8fb83f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = PPO2('MlpPolicy', \"CartPole-v1\", verbose=1).learn(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating environment from the given name, wrapped in a DummyVecEnv.\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00022001716 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.062         |\n",
            "| fps                | 278           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 0.69295824    |\n",
            "| policy_loss        | -0.005195465  |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.31e-05      |\n",
            "| total_timesteps    | 128           |\n",
            "| value_loss         | 38.741753     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 7.630998e-05 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | 0.00748      |\n",
            "| fps                | 446          |\n",
            "| n_updates          | 2            |\n",
            "| policy_entropy     | 0.6920499    |\n",
            "| policy_loss        | 7.297669e-05 |\n",
            "| serial_timesteps   | 256          |\n",
            "| time_elapsed       | 0.461        |\n",
            "| total_timesteps    | 256          |\n",
            "| value_loss         | 50.055187    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 6.166887e-06   |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | -0.00128       |\n",
            "| fps                | 482            |\n",
            "| n_updates          | 3              |\n",
            "| policy_entropy     | 0.6923027      |\n",
            "| policy_loss        | -0.00047565415 |\n",
            "| serial_timesteps   | 384            |\n",
            "| time_elapsed       | 0.748          |\n",
            "| total_timesteps    | 384            |\n",
            "| value_loss         | 66.5439        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.89403e-05   |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0237       |\n",
            "| fps                | 493           |\n",
            "| n_updates          | 4             |\n",
            "| policy_entropy     | 0.6902864     |\n",
            "| policy_loss        | -0.0020101897 |\n",
            "| serial_timesteps   | 512           |\n",
            "| time_elapsed       | 1.02          |\n",
            "| total_timesteps    | 512           |\n",
            "| value_loss         | 48.29166      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00026911922 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00328      |\n",
            "| fps                | 471           |\n",
            "| n_updates          | 5             |\n",
            "| policy_entropy     | 0.6873436     |\n",
            "| policy_loss        | -0.0049281    |\n",
            "| serial_timesteps   | 640           |\n",
            "| time_elapsed       | 1.28          |\n",
            "| total_timesteps    | 640           |\n",
            "| value_loss         | 40.53576      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00010242046 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0326        |\n",
            "| fps                | 422           |\n",
            "| n_updates          | 6             |\n",
            "| policy_entropy     | 0.6826819     |\n",
            "| policy_loss        | 0.00031948532 |\n",
            "| serial_timesteps   | 768           |\n",
            "| time_elapsed       | 1.55          |\n",
            "| total_timesteps    | 768           |\n",
            "| value_loss         | 27.480148     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.711196e-06   |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | -0.0352        |\n",
            "| fps                | 496            |\n",
            "| n_updates          | 7              |\n",
            "| policy_entropy     | 0.6857159      |\n",
            "| policy_loss        | -5.4778997e-05 |\n",
            "| serial_timesteps   | 896            |\n",
            "| time_elapsed       | 1.85           |\n",
            "| total_timesteps    | 896            |\n",
            "| value_loss         | 87.650894      |\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se8SHBN17Fy4",
        "outputId": "96314f59-a570-4487-bfbb-c6f6e34ade94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#YJ\n",
        "#이전방식\n",
        "env = gym.make('CartPole-v1')\n",
        "model = PPO2(MlpPolicy, env, verbose=1)\n",
        "model.learn(total_timesteps=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrapping the env in a DummyVecEnv.\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00014336246 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0098       |\n",
            "| fps                | 286           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 0.69299984    |\n",
            "| policy_loss        | -0.0033858928 |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.84e-05      |\n",
            "| total_timesteps    | 128           |\n",
            "| value_loss         | 40.028652     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.52109e-05   |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0178        |\n",
            "| fps                | 475           |\n",
            "| n_updates          | 2             |\n",
            "| policy_entropy     | 0.6924134     |\n",
            "| policy_loss        | -0.0026756327 |\n",
            "| serial_timesteps   | 256           |\n",
            "| time_elapsed       | 0.448         |\n",
            "| total_timesteps    | 256           |\n",
            "| value_loss         | 75.49992      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.5783624e-05 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0571       |\n",
            "| fps                | 452           |\n",
            "| n_updates          | 3             |\n",
            "| policy_entropy     | 0.6903024     |\n",
            "| policy_loss        | -0.0010451393 |\n",
            "| serial_timesteps   | 384           |\n",
            "| time_elapsed       | 0.718         |\n",
            "| total_timesteps    | 384           |\n",
            "| value_loss         | 26.22456      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00010088295 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0212        |\n",
            "| fps                | 481           |\n",
            "| n_updates          | 4             |\n",
            "| policy_entropy     | 0.68955535    |\n",
            "| policy_loss        | -0.002412296  |\n",
            "| serial_timesteps   | 512           |\n",
            "| time_elapsed       | 1             |\n",
            "| total_timesteps    | 512           |\n",
            "| value_loss         | 37.087784     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.895431e-05  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0795        |\n",
            "| fps                | 458           |\n",
            "| n_updates          | 5             |\n",
            "| policy_entropy     | 0.6865814     |\n",
            "| policy_loss        | -0.0007583995 |\n",
            "| serial_timesteps   | 640           |\n",
            "| time_elapsed       | 1.27          |\n",
            "| total_timesteps    | 640           |\n",
            "| value_loss         | 30.92265      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.0168744e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | 0.0276         |\n",
            "| fps                | 503            |\n",
            "| n_updates          | 6              |\n",
            "| policy_entropy     | 0.686058       |\n",
            "| policy_loss        | -0.00040218816 |\n",
            "| serial_timesteps   | 768            |\n",
            "| time_elapsed       | 1.55           |\n",
            "| total_timesteps    | 768            |\n",
            "| value_loss         | 41.769894      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.8128741e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | -0.0312        |\n",
            "| fps                | 478            |\n",
            "| n_updates          | 7              |\n",
            "| policy_entropy     | 0.68517184     |\n",
            "| policy_loss        | -0.00037424825 |\n",
            "| serial_timesteps   | 896            |\n",
            "| time_elapsed       | 1.8            |\n",
            "| total_timesteps    | 896            |\n",
            "| value_loss         | 39.24869       |\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fee2cc88128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBf84jU05mgi"
      },
      "source": [
        "## Train a DQN agent\n",
        "\n",
        "In the previous example, we have used PPO, which one of the many algorithms provided by stable-baselines.\n",
        "- 앞 선 예제는 stabel-baselines가 제공하는 많은 알고리듬 중 하나인 PPO를 이용\n",
        "\n",
        "In the next example, we are going train a [Deep Q-Network agent (DQN)](https://stable-baselines.readthedocs.io/en/master/modules/dqn.html), and try to see possible improvements provided by its extensions (Double-DQN, Dueling-DQN, Prioritized Experience Replay).\n",
        "- 다음 예제에서는 DQN을 이용해서 학습\n",
        "- Double-DQN, Dueling-DQN, Prioritized Experience Replay같은 확장알고리즘들에 의해 제공되는 가능한 개선점들을 보겠음\n",
        "\n",
        "The essential point of this section is to show you how simple it is to tweak hyperparameters.\n",
        "- 이 섹션의 필수 포인트는 hyperparameter를 조정하는 것이 매우 간단하는 것을 보여주는 것\n",
        "\n",
        "The main advantage of stable-baselines is that it provides a common interface to use the algorithms, so the code will be quite similar.\n",
        "- stable-baselines의 주요 이점은 알고리즘 사용에 공통적인 interface를 제공한다는 것임. 코드 사용이 매우 유사해짐\n",
        "\n",
        "\n",
        "DQN paper: https://arxiv.org/abs/1312.5602\n",
        "\n",
        "Dueling DQN: https://arxiv.org/abs/1511.06581\n",
        "\n",
        "Double-Q Learning: https://arxiv.org/abs/1509.06461\n",
        "\n",
        "Prioritized Experience Replay: https://arxiv.org/abs/1511.05952"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kikNl-tT92Ae"
      },
      "source": [
        "### Vanilla DQN: DQN without extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdLdYABz8TJx",
        "outputId": "3746ed8e-e863-4594-8cba-862d0b56451c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Same as before we instantiate the agent along with the environment\n",
        "from stable_baselines import DQN\n",
        "\n",
        "# Deactivate all the DQN extensions to have the original version\n",
        "# In practice, it is recommend to have them activated\n",
        "# 본 예제에서는 모든 확장 기능을 비활성화시킴. 실제에서는 모두 활성화하길 추천함\n",
        "kwargs = {'double_q': False, 'prioritized_replay': False, 'policy_kwargs': dict(dueling=False)}\n",
        "\n",
        "# Note that the MlpPolicy of DQN is different from the one of PPO\n",
        "# but stable-baselines handles that automatically if you pass a string\n",
        "# DQN의 MlpPolicy는 PPO의 그것과 다르지만 string argument를 이용해서 자동으로 적절할 MlpPolicy가 선택됨\n",
        "dqn_model = DQN('MlpPolicy', 'CartPole-v1', verbose=1, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating environment from the given name, wrapped in a DummyVecEnv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4A_IOZ_9fzW",
        "outputId": "b9e6bc3e-b39f-45a6-9743-adc8de3338f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Random Agent, before training\n",
        "mean_reward_before_train = evaluate(dqn_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 14.46 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B-8y3MKIAAn",
        "outputId": "6aec721f-cb16-47df-f788-7a1b3aa5bb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "mean_reward, std_reward = evaluate_policy(dqn_model, env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward:13.85 +/- 11.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wbuvAKk9spH",
        "outputId": "f5357e61-ef9b-4312-8428-01cdb559548e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the agent for 10000 steps\n",
        "dqn_model.learn(total_timesteps=10000, log_interval=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 81       |\n",
            "| episodes                | 10       |\n",
            "| mean 100 episode reward | 21.2     |\n",
            "| steps                   | 191      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 63       |\n",
            "| episodes                | 20       |\n",
            "| mean 100 episode reward | 19.7     |\n",
            "| steps                   | 375      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 49       |\n",
            "| episodes                | 30       |\n",
            "| mean 100 episode reward | 17.8     |\n",
            "| steps                   | 516      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 38       |\n",
            "| episodes                | 40       |\n",
            "| mean 100 episode reward | 16.2     |\n",
            "| steps                   | 632      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 25       |\n",
            "| episodes                | 50       |\n",
            "| mean 100 episode reward | 15.6     |\n",
            "| steps                   | 765      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 14       |\n",
            "| episodes                | 60       |\n",
            "| mean 100 episode reward | 14.8     |\n",
            "| steps                   | 871      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 3        |\n",
            "| episodes                | 70       |\n",
            "| mean 100 episode reward | 14.2     |\n",
            "| steps                   | 980      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 80       |\n",
            "| mean 100 episode reward | 13.6     |\n",
            "| steps                   | 1074     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 90       |\n",
            "| mean 100 episode reward | 13.3     |\n",
            "| steps                   | 1185     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 100      |\n",
            "| mean 100 episode reward | 13       |\n",
            "| steps                   | 1286     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 110      |\n",
            "| mean 100 episode reward | 11.9     |\n",
            "| steps                   | 1378     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 120      |\n",
            "| mean 100 episode reward | 10.9     |\n",
            "| steps                   | 1470     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 130      |\n",
            "| mean 100 episode reward | 10.5     |\n",
            "| steps                   | 1567     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 140      |\n",
            "| mean 100 episode reward | 10.3     |\n",
            "| steps                   | 1660     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 150      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 1751     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 160      |\n",
            "| mean 100 episode reward | 10       |\n",
            "| steps                   | 1873     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 170      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 1972     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 180      |\n",
            "| mean 100 episode reward | 10       |\n",
            "| steps                   | 2075     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 190      |\n",
            "| mean 100 episode reward | 10       |\n",
            "| steps                   | 2184     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 200      |\n",
            "| mean 100 episode reward | 10.2     |\n",
            "| steps                   | 2309     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 210      |\n",
            "| mean 100 episode reward | 10.5     |\n",
            "| steps                   | 2426     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 220      |\n",
            "| mean 100 episode reward | 10.8     |\n",
            "| steps                   | 2551     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 230      |\n",
            "| mean 100 episode reward | 11.7     |\n",
            "| steps                   | 2735     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 240      |\n",
            "| mean 100 episode reward | 13.6     |\n",
            "| steps                   | 3019     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 250      |\n",
            "| mean 100 episode reward | 21.6     |\n",
            "| steps                   | 3915     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 260      |\n",
            "| mean 100 episode reward | 33.7     |\n",
            "| steps                   | 5244     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 270      |\n",
            "| mean 100 episode reward | 52       |\n",
            "| steps                   | 7172     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 280      |\n",
            "| mean 100 episode reward | 67.8     |\n",
            "| steps                   | 8850     |\n",
            "--------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.deepq.dqn.DQN at 0x7fee2b296a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQTdpYv9xJN",
        "outputId": "cfb3bab0-8970-463b-cf88-f87a411d9faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward = evaluate(dqn_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 178.89 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap-t5aC7IOLM",
        "outputId": "3b24806d-6222-4566-d62c-c6285a043d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# YJ\n",
        "mean_reward, std_reward = evaluate_policy(dqn_model, env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward:179.78 +/- 16.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFJvqsMl96l7"
      },
      "source": [
        "### DQN + Prioritized Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roCSjGu69-lA",
        "outputId": "7a83c6a6-19e7-40ac-e7ca-5c8d2edbc136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Activate only the prioritized replay\n",
        "# 'prioritized replay'만 활성화\n",
        "kwargs = {'double_q': False, 'prioritized_replay': True, 'policy_kwargs': dict(dueling=False)}\n",
        "\n",
        "dqn_per_model = DQN('MlpPolicy', 'CartPole-v1', verbose=1, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating environment from the given name, wrapped in a DummyVecEnv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLnLhos5-lRm",
        "outputId": "3ea0fa76-b9c8-4b1b-d625-59f27e62f29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dqn_per_model.learn(total_timesteps=10000, log_interval=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| % time spent exploring  | 82       |\n",
            "| episodes                | 10       |\n",
            "| mean 100 episode reward | 19.7     |\n",
            "| steps                   | 177      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 67       |\n",
            "| episodes                | 20       |\n",
            "| mean 100 episode reward | 17.3     |\n",
            "| steps                   | 328      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 51       |\n",
            "| episodes                | 30       |\n",
            "| mean 100 episode reward | 16.9     |\n",
            "| steps                   | 491      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 38       |\n",
            "| episodes                | 40       |\n",
            "| mean 100 episode reward | 16.1     |\n",
            "| steps                   | 628      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 26       |\n",
            "| episodes                | 50       |\n",
            "| mean 100 episode reward | 15.3     |\n",
            "| steps                   | 752      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 16       |\n",
            "| episodes                | 60       |\n",
            "| mean 100 episode reward | 14.5     |\n",
            "| steps                   | 853      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 6        |\n",
            "| episodes                | 70       |\n",
            "| mean 100 episode reward | 13.9     |\n",
            "| steps                   | 956      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 80       |\n",
            "| mean 100 episode reward | 13.3     |\n",
            "| steps                   | 1047     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 90       |\n",
            "| mean 100 episode reward | 12.9     |\n",
            "| steps                   | 1145     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 100      |\n",
            "| mean 100 episode reward | 12.7     |\n",
            "| steps                   | 1258     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 110      |\n",
            "| mean 100 episode reward | 11.9     |\n",
            "| steps                   | 1367     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 120      |\n",
            "| mean 100 episode reward | 11.4     |\n",
            "| steps                   | 1464     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 130      |\n",
            "| mean 100 episode reward | 10.6     |\n",
            "| steps                   | 1554     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 140      |\n",
            "| mean 100 episode reward | 10.2     |\n",
            "| steps                   | 1653     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 150      |\n",
            "| mean 100 episode reward | 10       |\n",
            "| steps                   | 1753     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 160      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 1844     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 170      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 1942     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 180      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 2039     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 190      |\n",
            "| mean 100 episode reward | 9.9      |\n",
            "| steps                   | 2134     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 200      |\n",
            "| mean 100 episode reward | 9.7      |\n",
            "| steps                   | 2230     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 210      |\n",
            "| mean 100 episode reward | 9.6      |\n",
            "| steps                   | 2327     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 220      |\n",
            "| mean 100 episode reward | 9.6      |\n",
            "| steps                   | 2421     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 230      |\n",
            "| mean 100 episode reward | 9.6      |\n",
            "| steps                   | 2518     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 240      |\n",
            "| mean 100 episode reward | 9.6      |\n",
            "| steps                   | 2613     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 250      |\n",
            "| mean 100 episode reward | 9.7      |\n",
            "| steps                   | 2722     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 260      |\n",
            "| mean 100 episode reward | 10.7     |\n",
            "| steps                   | 2914     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 270      |\n",
            "| mean 100 episode reward | 15.6     |\n",
            "| steps                   | 3502     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 280      |\n",
            "| mean 100 episode reward | 29.8     |\n",
            "| steps                   | 5018     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 290      |\n",
            "| mean 100 episode reward | 47       |\n",
            "| steps                   | 6831     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 300      |\n",
            "| mean 100 episode reward | 66.3     |\n",
            "| steps                   | 8865     |\n",
            "--------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.deepq.dqn.DQN at 0x7fee2f63d6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQjF5S_g-mFN",
        "outputId": "c46fcf08-c70f-4310-adc4-1c3c82e64b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward = evaluate(dqn_per_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 196.15 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skny8MUN9_Ky"
      },
      "source": [
        "### DQN + Prioritized Experience Replay + Double Q-Learning + Dueling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCys-Vg-yYR",
        "outputId": "56e1ac09-5da7-4f66-e2c1-9a34c0ae3361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Activate all extensions\n",
        "kwargs = {'double_q': True, 'prioritized_replay': True, 'policy_kwargs': dict(dueling=True)}\n",
        "\n",
        "dqn_full_model = DQN('MlpPolicy', 'CartPole-v1', verbose=1, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating environment from the given name, wrapped in a DummyVecEnv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHGB-VN-81O",
        "outputId": "eaadcb39-07a5-4562-e8fb-b283b32f9768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dqn_full_model.learn(total_timesteps=10000, log_interval=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| % time spent exploring  | 83       |\n",
            "| episodes                | 10       |\n",
            "| mean 100 episode reward | 18.2     |\n",
            "| steps                   | 164      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 69       |\n",
            "| episodes                | 20       |\n",
            "| mean 100 episode reward | 16.4     |\n",
            "| steps                   | 312      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 56       |\n",
            "| episodes                | 30       |\n",
            "| mean 100 episode reward | 15.2     |\n",
            "| steps                   | 442      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 44       |\n",
            "| episodes                | 40       |\n",
            "| mean 100 episode reward | 14.6     |\n",
            "| steps                   | 568      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 33       |\n",
            "| episodes                | 50       |\n",
            "| mean 100 episode reward | 13.8     |\n",
            "| steps                   | 678      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 23       |\n",
            "| episodes                | 60       |\n",
            "| mean 100 episode reward | 13.2     |\n",
            "| steps                   | 781      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 13       |\n",
            "| episodes                | 70       |\n",
            "| mean 100 episode reward | 12.8     |\n",
            "| steps                   | 884      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 3        |\n",
            "| episodes                | 80       |\n",
            "| mean 100 episode reward | 12.5     |\n",
            "| steps                   | 984      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 90       |\n",
            "| mean 100 episode reward | 12.1     |\n",
            "| steps                   | 1077     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 100      |\n",
            "| mean 100 episode reward | 12       |\n",
            "| steps                   | 1192     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 110      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 1346     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 120      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 1491     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 130      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 1625     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 140      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 1750     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 150      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 1856     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 160      |\n",
            "| mean 100 episode reward | 11.9     |\n",
            "| steps                   | 1969     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 170      |\n",
            "| mean 100 episode reward | 11.9     |\n",
            "| steps                   | 2077     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 180      |\n",
            "| mean 100 episode reward | 12.1     |\n",
            "| steps                   | 2191     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 190      |\n",
            "| mean 100 episode reward | 12.3     |\n",
            "| steps                   | 2307     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 200      |\n",
            "| mean 100 episode reward | 12.4     |\n",
            "| steps                   | 2433     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 210      |\n",
            "| mean 100 episode reward | 12.1     |\n",
            "| steps                   | 2557     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 220      |\n",
            "| mean 100 episode reward | 12       |\n",
            "| steps                   | 2690     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 230      |\n",
            "| mean 100 episode reward | 11.8     |\n",
            "| steps                   | 2810     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 240      |\n",
            "| mean 100 episode reward | 11.9     |\n",
            "| steps                   | 2937     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 250      |\n",
            "| mean 100 episode reward | 12.1     |\n",
            "| steps                   | 3070     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 260      |\n",
            "| mean 100 episode reward | 12.4     |\n",
            "| steps                   | 3211     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 270      |\n",
            "| mean 100 episode reward | 12.8     |\n",
            "| steps                   | 3360     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 280      |\n",
            "| mean 100 episode reward | 13.1     |\n",
            "| steps                   | 3502     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 290      |\n",
            "| mean 100 episode reward | 13.8     |\n",
            "| steps                   | 3685     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 300      |\n",
            "| mean 100 episode reward | 15.1     |\n",
            "| steps                   | 3944     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 310      |\n",
            "| mean 100 episode reward | 26.2     |\n",
            "| steps                   | 5181     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 320      |\n",
            "| mean 100 episode reward | 44.1     |\n",
            "| steps                   | 7099     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 330      |\n",
            "| mean 100 episode reward | 61.6     |\n",
            "| steps                   | 8968     |\n",
            "--------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.deepq.dqn.DQN at 0x7fee2f67ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cHRULdp--nN",
        "outputId": "f48ff96a-99e2-409c-c8e6-f05d570fa4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mean_reward = evaluate(dqn_per_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 201.47 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Q9dR3UC5Zb"
      },
      "source": [
        "In this particular example, the extensions does not seem to give any improvement compared to the simple DQN version.\n",
        "- Mean reward\n",
        "  - simple: : 178.89, one_extension: 196.15, all_extension: 201.47\n",
        "\n",
        "They are several reasons for that:\n",
        "- extension이 큰 개선효과를 나타내지 못한 것에 다음과 같은 이유가 있음\n",
        "1. `CartPole-v1` is a pretty simple environment\n",
        "- 'CartPole-v1'은 꽤 단순한 환경임\n",
        "2. We trained DQN for very few timesteps, not enough to see any difference\n",
        "- 어떤 차별점을 보기에는 너무 작은 기간동안만 학습했음\n",
        "3. The default hyperparameters for DQN are tuned for atari games, where the number of training timesteps is much larger (10^6) and input observations are images\n",
        "- DQN을 Default HP값은 atari games에 맞춰져 있음. atari game에서의 training timesteps는 훨씬 더 크고(10^6), input observation이 이미지임\n",
        "4. We have only compared one random seed per experiment\n",
        "- 실험 당 오직 하나의 랜덤 시드만 비교했음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrI6f5fWnzp-"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook we have seen:\n",
        "- how to define and train a RL model using stable baselines, it takes only one line of code ;)\n",
        "- how to use different RL algorithms and change some hyperparameters\n",
        "\n",
        "- 이번 노트북을 통해 \n",
        "  - stable baselines로 RL model을 정의하고 학습하는 방법을 배움\n",
        "  - 서로 다른 RL 알고리즘을 이용하는 방법과 약간의 HP를 바꾸는 방법을 배움"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjbqDfFYKJ7o"
      },
      "source": [
        "### DQN training step 증가시켜 비교해보기 (YJ)\n",
        "simple: : 178.89, one_extension: 196.15, all_extension: 201.47"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ji3gbNDkf7",
        "outputId": "a90f1647-3755-496a-92aa-e67b82f82bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Simple(YJ)\n",
        "kwargs = {'double_q': False, 'prioritized_replay': False, 'policy_kwargs': dict(dueling=False)}\n",
        "dqn_model = DQN('MlpPolicy', 'CartPole-v1', verbose=0, **kwargs)\n",
        "dqn_model.learn(total_timesteps=1000000, log_interval=10)\n",
        "mean_reward = evaluate(dqn_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 96.54 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jGafm_JK45I",
        "outputId": "f6c3fbad-872e-489c-c7ea-e8edefadfb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# One_extension(YJ)\n",
        "kwargs = {'double_q': False, 'prioritized_replay': True, 'policy_kwargs': dict(dueling=False)}\n",
        "dqn_model = DQN('MlpPolicy', 'CartPole-v1', verbose=0, **kwargs)\n",
        "dqn_model.learn(total_timesteps=1000000, log_interval=10)\n",
        "mean_reward = evaluate(dqn_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 500.0 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL0rQyEWK_qw",
        "outputId": "5fe14c9f-508d-4bf5-b425-f8b5dd1c13ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# All_extensions(YJ)\n",
        "kwargs = {'double_q': True, 'prioritized_replay': True, 'policy_kwargs': dict(dueling=True)}\n",
        "dqn_model = DQN('MlpPolicy', 'CartPole-v1', verbose=0, **kwargs)\n",
        "dqn_model.learn(total_timesteps=1000000, log_interval=10)\n",
        "mean_reward = evaluate(dqn_model, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 96.73 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhTY5y6VLEr5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}