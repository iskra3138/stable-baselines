{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "git_based_Stable_baselines_A2C_HPO",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/stable-baselines/blob/main/git_based_Stable_baselines_A2C_HPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC5luhybVmzc"
      },
      "source": [
        "# 필요한 Library 및 git repo 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdOUMxVJ8oyl"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "\n",
        "!apt install swig\n",
        "!pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHjuNXTFil9c"
      },
      "source": [
        "!git clone --recursive https://github.com/araffin/rl-baselines-zoo.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK7WmkfxoYKP"
      },
      "source": [
        "# Directpry change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC8jjDk9i5SD"
      },
      "source": [
        "%cd /content/rl-baselines-zoo/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUGpS9r_WAti"
      },
      "source": [
        "# TF 1.X 선택 및 필요 모듈 호출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8E7nW1aWBNE"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import gym\n",
        "import argparse\n",
        "import time\n",
        "import yaml\n",
        "\n",
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner, MedianPruner\n",
        "from optuna.samplers import RandomSampler, TPESampler\n",
        "from optuna.integration.skopt import SkoptSampler\n",
        "\n",
        "from stable_baselines import SAC, TD3\n",
        "from stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
        "from stable_baselines.common.vec_env import VecNormalize, DummyVecEnv, VecEnv\n",
        "from stable_baselines.common import set_global_seeds\n",
        "from stable_baselines.bench import Monitor\n",
        "\n",
        "from utils import make_env, ALGOS, linear_schedule, get_latest_run_id, get_wrapper_class\n",
        "from utils.utils import StoreDict\n",
        "\n",
        "from utils.callbacks import TrialEvalCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMZd1hubmEC7"
      },
      "source": [
        "# <font color='red'> Arguments 입력 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kVld8eIIxQ"
      },
      "source": [
        "# Default Values\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--env', type=str, default=\"CartPole-v1\", help='environment ID')\n",
        "parser.add_argument('-tb', '--tensorboard-log', help='Tensorboard log dir', default='', type=str)\n",
        "parser.add_argument('-i', '--trained-agent', help='Path to a pretrained agent to continue training',\n",
        "                    default='', type=str)\n",
        "parser.add_argument('--algo', help='RL Algorithm', default='ppo2',\n",
        "                    type=str, required=False, choices=list(ALGOS.keys()))\n",
        "parser.add_argument('-n', '--n-timesteps', help='Overwrite the number of timesteps', default=-1,\n",
        "                    type=int)\n",
        "parser.add_argument('--log-interval', help='Override log interval (default: -1, no change)', default=-1,\n",
        "                    type=int)\n",
        "parser.add_argument('--eval-freq', help='Evaluate the agent every n steps (if negative, no evaluation)',\n",
        "                    default=10000, type=int)\n",
        "parser.add_argument('--eval-episodes', help='Number of episodes to use for evaluation',\n",
        "                    default=5, type=int)\n",
        "parser.add_argument('--save-freq', help='Save the model every n steps (if negative, no checkpoint)',\n",
        "                    default=-1, type=int)\n",
        "parser.add_argument('-f', '--log-folder', help='Log folder', type=str, default='logs')\n",
        "parser.add_argument('--seed', help='Random generator seed', type=int, default=0)\n",
        "parser.add_argument('--n-trials', help='Number of trials for optimizing hyperparameters', type=int, default=10)\n",
        "parser.add_argument('-optimize', '--optimize-hyperparameters', action='store_true', default=False,\n",
        "                    help='Run hyperparameters search')\n",
        "parser.add_argument('--n-jobs', help='Number of parallel jobs when optimizing hyperparameters', type=int, default=1)\n",
        "parser.add_argument('--sampler', help='Sampler to use when optimizing hyperparameters', type=str,\n",
        "                    default='tpe', choices=['random', 'tpe', 'skopt'])\n",
        "parser.add_argument('--pruner', help='Pruner to use when optimizing hyperparameters', type=str,\n",
        "                    default='median', choices=['halving', 'median', 'none'])\n",
        "parser.add_argument('--verbose', help='Verbose mode (0: no output, 1: INFO)', default=1,\n",
        "                    type=int)\n",
        "parser.add_argument('--gym-packages', type=str, nargs='+', default=[],\n",
        "                    help='Additional external Gym environemnt package modules to import (e.g. gym_minigrid)')\n",
        "parser.add_argument('-params', '--hyperparams', type=str, nargs='+', action=StoreDict,\n",
        "                    help='Overwrite hyperparameter (e.g. learning_rate:0.01 train_freq:10)')\n",
        "parser.add_argument('-uuid', '--uuid', action='store_true', default=False,\n",
        "                    help='Ensure that the run has a unique ID')\n",
        "parser.add_argument('--env-kwargs', type=str, nargs='+', action=StoreDict,\n",
        "                    help='Optional keyword argument to pass to the env constructor')\n",
        "args = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BguZFVRyYmyH"
      },
      "source": [
        "# Custom Values\n",
        "args.algo = 'a2c'\n",
        "args.log_folder = './log'\n",
        "env_id = 'CartPole-v1'\n",
        "tensorboard_log = './tb_log'\n",
        "normalize = False\n",
        "n_envs = 1\n",
        "seed = 0\n",
        "log_dir ='./log' \n",
        "save_path = './save'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IafCwnGalOxa"
      },
      "source": [
        "# Load hyperparameters from yaml file\n",
        "with open('hyperparams/{}.yml'.format(args.algo), 'r') as f:\n",
        "    hyperparams_dict = yaml.safe_load(f)\n",
        "    if env_id in list(hyperparams_dict.keys()):\n",
        "        hyperparams = hyperparams_dict[env_id]\n",
        "    elif is_atari:\n",
        "        hyperparams = hyperparams_dict['atari']\n",
        "    else:\n",
        "        raise ValueError(\"Hyperparameters not found for {}-{}\".format(args.algo, env_id))\n",
        "\n",
        "# Delete keys so the dict can be pass to the model constructor\n",
        "if 'n_envs' in hyperparams.keys():\n",
        "    del hyperparams['n_envs']\n",
        "del hyperparams['n_timesteps']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to-_8RhwWS-h"
      },
      "source": [
        "# <font color='red'> HPO 탐색공간 입력 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojC69PiC9YNb"
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/utils/hyperparams_opt.py\n",
        "# n_steps = 128로 고정\n",
        "def sample_a2c_params(trial):\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparams.\n",
        "\n",
        "    :param trial: (optuna.trial)\n",
        "    :return: (dict)\n",
        "    \"\"\"\n",
        "    gamma = trial.suggest_categorical('gamma', [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
        "    #n_steps = trial.suggest_categorical('n_steps', [8, 16, 32, 64, 128, 256, 512, 1024, 2048])\n",
        "    n_steps = trial.suggest_categorical('n_steps', [128])\n",
        "    lr_schedule = trial.suggest_categorical('lr_schedule', ['linear', 'constant'])\n",
        "    learning_rate = trial.suggest_loguniform('lr', 1e-5, 1)\n",
        "    ent_coef = trial.suggest_loguniform('ent_coef', 0.00000001, 0.1)\n",
        "    vf_coef = trial.suggest_uniform('vf_coef', 0, 1)\n",
        "    # normalize = trial.suggest_categorical('normalize', [True, False])\n",
        "    # TODO: take into account the normalization (also for the test env)\n",
        "\n",
        "    return {\n",
        "        'n_steps': n_steps,\n",
        "        'gamma': gamma,\n",
        "        'learning_rate': learning_rate,\n",
        "        'lr_schedule': lr_schedule,\n",
        "        'ent_coef': ent_coef,\n",
        "        'vf_coef': vf_coef\n",
        "    }\n",
        "\n",
        "HYPERPARAMS_SAMPLER = {\n",
        "    'a2c': sample_a2c_params,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ahmQzoyWLHt"
      },
      "source": [
        "# 환경 및 모델 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbiCVIxilo2Y"
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/utils/utils.py\n",
        "def make_env(env_id, rank=0, seed=0, log_dir=None, wrapper_class=None, env_kwargs=None):\n",
        "    \"\"\"\n",
        "    Helper function to multiprocess training\n",
        "    and log the progress.\n",
        "    :param env_id: (str)\n",
        "    :param rank: (int)\n",
        "    :param seed: (int)\n",
        "    :param log_dir: (str)\n",
        "    :param wrapper: (type) a subclass of gym.Wrapper to wrap the original\n",
        "                    env with\n",
        "    :param env_kwargs: (Dict[str, Any]) Optional keyword argument to pass to the env constructor\n",
        "    \"\"\"\n",
        "    if log_dir is not None:\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    if env_kwargs is None:\n",
        "        env_kwargs = {}\n",
        "\n",
        "    def _init():\n",
        "        set_global_seeds(seed + rank)\n",
        "        env = gym.make(env_id, **env_kwargs)\n",
        "\n",
        "        # Dict observation space is currently not supported.\n",
        "        # https://github.com/hill-a/stable-baselines/issues/321\n",
        "        # We allow a Gym env wrapper (a subclass of gym.Wrapper)\n",
        "        if wrapper_class:\n",
        "            env = wrapper_class(env)\n",
        "\n",
        "        env.seed(seed + rank)\n",
        "        log_file = os.path.join(log_dir, str(rank)) if log_dir is not None else None\n",
        "        env = Monitor(env, log_file)\n",
        "        return env\n",
        "\n",
        "    return _init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIkC_P3ngSda"
      },
      "source": [
        "# obtain a class object from a wrapper name string in hyperparams\n",
        "# and delete the entry\n",
        "env_wrapper = get_wrapper_class(hyperparams)\n",
        "if 'env_wrapper' in hyperparams.keys():\n",
        "    del hyperparams['env_wrapper']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWSSBRRWgkJP"
      },
      "source": [
        "env_kwargs = {} if args.env_kwargs is None else args.env_kwargs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6GmAoXeTjoM"
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/train.py\n",
        "is_atari = False\n",
        "algo_ = []\n",
        "def create_env(n_envs, eval_env=False, no_log=False):\n",
        "    \"\"\"\n",
        "    Create the environment and wrap it if necessary\n",
        "    :param n_envs: (int)\n",
        "    :param eval_env: (bool) Whether is it an environment used for evaluation or not\n",
        "    :param no_log: (bool) Do not log training when doing hyperparameter optim\n",
        "        (issue with writing the same file)\n",
        "    :return: (Union[gym.Env, VecEnv])\n",
        "    \"\"\"\n",
        "    global hyperparams\n",
        "    global env_kwargs\n",
        "\n",
        "    # Do not log eval env (issue with writing the same file)\n",
        "    log_dir = None if eval_env or no_log else save_path\n",
        "\n",
        "    if is_atari:\n",
        "        if args.verbose > 0:\n",
        "            print(\"Using Atari wrapper\")\n",
        "        env = make_atari_env(env_id, num_env=n_envs, seed=args.seed)\n",
        "        # Frame-stacking with 4 frames\n",
        "        env = VecFrameStack(env, n_stack=4)\n",
        "    elif algo_ in ['dqn', 'ddpg']:\n",
        "        if hyperparams.get('normalize', False):\n",
        "            print(\"WARNING: normalization not supported yet for DDPG/DQN\")\n",
        "        env = gym.make(env_id, **env_kwargs)\n",
        "        env.seed(args.seed)\n",
        "        if env_wrapper is not None:\n",
        "            env = env_wrapper(env)\n",
        "    else:\n",
        "        if n_envs == 1:\n",
        "            env = DummyVecEnv([make_env(env_id, 0, args.seed, wrapper_class=env_wrapper, log_dir=log_dir, env_kwargs=env_kwargs)])\n",
        "        else:\n",
        "            # env = SubprocVecEnv([make_env(env_id, i, args.seed) for i in range(n_envs)])\n",
        "            # On most env, SubprocVecEnv does not help and is quite memory hungry\n",
        "            env = DummyVecEnv([make_env(env_id, i, args.seed, log_dir=log_dir,\n",
        "                                        wrapper_class=env_wrapper, env_kwargs=env_kwargs) for i in range(n_envs)])\n",
        "        if normalize:\n",
        "            # Copy to avoid changing default values by reference\n",
        "            local_normalize_kwargs = normalize_kwargs.copy()\n",
        "            # Do not normalize reward for env used for evaluation\n",
        "            if eval_env:\n",
        "                if len(local_normalize_kwargs) > 0:\n",
        "                    local_normalize_kwargs['norm_reward'] = False\n",
        "                else:\n",
        "                    local_normalize_kwargs = {'norm_reward': False}\n",
        "\n",
        "            if args.verbose > 0:\n",
        "                if len(local_normalize_kwargs) > 0:\n",
        "                    print(\"Normalization activated: {}\".format(local_normalize_kwargs))\n",
        "                else:\n",
        "                    print(\"Normalizing input and reward\")\n",
        "            env = VecNormalize(env, **local_normalize_kwargs)\n",
        "\n",
        "    # Optional Frame-stacking\n",
        "    if hyperparams.get('frame_stack', False):\n",
        "        n_stack = hyperparams['frame_stack']\n",
        "        env = VecFrameStack(env, n_stack)\n",
        "        print(\"Stacking {} frames\".format(n_stack))\n",
        "    if args.algo == 'her':\n",
        "        # Wrap the env if need to flatten the dict obs\n",
        "        if isinstance(env, VecEnv):\n",
        "            env = _UnvecWrapper(env)\n",
        "        env = HERGoalEnvWrapper(env)\n",
        "    return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI4S3WEvpUhc"
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/train.py\n",
        "\n",
        "def create_model(*_args, **kwargs):\n",
        "    \"\"\"\n",
        "    Helper to create a model with different hyperparameters\n",
        "    \"\"\"\n",
        "    return ALGOS[args.algo](env=create_env(n_envs, no_log=True), tensorboard_log=tensorboard_log,\n",
        "                            verbose=0, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpsALainpMAu"
      },
      "source": [
        "# Optimization 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8GNeci-0dQ0"
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/utils/hyperparams_opt.py\n",
        "def hyperparam_optimization(algo, model_fn, env_fn, n_trials=10, n_timesteps=5000, hyperparams=None,\n",
        "                            n_jobs=1, sampler_method='random', pruner_method='halving',\n",
        "                            seed=0, verbose=1):\n",
        "    \"\"\"\n",
        "    :param algo: (str)\n",
        "    :param model_fn: (func) function that is used to instantiate the model\n",
        "    :param env_fn: (func) function that is used to instantiate the env\n",
        "    :param n_trials: (int) maximum number of trials for finding the best hyperparams\n",
        "    :param n_timesteps: (int) maximum number of timesteps per trial\n",
        "    :param hyperparams: (dict)\n",
        "    :param n_jobs: (int) number of parallel jobs\n",
        "    :param sampler_method: (str)\n",
        "    :param pruner_method: (str)\n",
        "    :param seed: (int)\n",
        "    :param verbose: (int)\n",
        "    :return: (pd.Dataframe) detailed result of the optimization\n",
        "    \"\"\"\n",
        "    # TODO: eval each hyperparams several times to account for noisy evaluation\n",
        "    # TODO: take into account the normalization (also for the test env -> sync obs_rms)\n",
        "    if hyperparams is None:\n",
        "        hyperparams = {}\n",
        "\n",
        "    n_startup_trials = 10\n",
        "    # test during 5 episodes\n",
        "    n_eval_episodes = 5\n",
        "    # evaluate every 20th of the maximum budget per iteration\n",
        "    n_evaluations = 20\n",
        "    eval_freq = int(n_timesteps / n_evaluations)\n",
        "\n",
        "    # n_warmup_steps: Disable pruner until the trial reaches the given number of step.\n",
        "    if sampler_method == 'random':\n",
        "        sampler = RandomSampler(seed=seed)\n",
        "    elif sampler_method == 'tpe':\n",
        "        sampler = TPESampler(n_startup_trials=n_startup_trials, seed=seed)\n",
        "    elif sampler_method == 'skopt':\n",
        "        # cf https://scikit-optimize.github.io/#skopt.Optimizer\n",
        "        # GP: gaussian process\n",
        "        # Gradient boosted regression: GBRT\n",
        "        sampler = SkoptSampler(skopt_kwargs={'base_estimator': \"GP\", 'acq_func': 'gp_hedge'})\n",
        "    else:\n",
        "        raise ValueError('Unknown sampler: {}'.format(sampler_method))\n",
        "\n",
        "    if pruner_method == 'halving':\n",
        "        pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=4, min_early_stopping_rate=0)\n",
        "    elif pruner_method == 'median':\n",
        "        pruner = MedianPruner(n_startup_trials=n_startup_trials, n_warmup_steps=n_evaluations // 3)\n",
        "    elif pruner_method == 'none':\n",
        "        # Do not prune\n",
        "        pruner = MedianPruner(n_startup_trials=n_trials, n_warmup_steps=n_evaluations)\n",
        "    else:\n",
        "        raise ValueError('Unknown pruner: {}'.format(pruner_method))\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(\"Sampler: {} - Pruner: {}\".format(sampler_method, pruner_method))\n",
        "\n",
        "    study = optuna.create_study(sampler=sampler, pruner=pruner)\n",
        "    algo_sampler = HYPERPARAMS_SAMPLER[algo]\n",
        "\n",
        "    def objective(trial):\n",
        "\n",
        "        kwargs = hyperparams.copy()\n",
        "\n",
        "        trial.model_class = None\n",
        "        if algo == 'her':\n",
        "            trial.model_class = hyperparams['model_class']\n",
        "\n",
        "        # Hack to use DDPG/TD3 noise sampler\n",
        "        if algo in ['ddpg', 'td3'] or trial.model_class in ['ddpg', 'td3']:\n",
        "            trial.n_actions = env_fn(n_envs=1).action_space.shape[0]\n",
        "        kwargs.update(algo_sampler(trial))\n",
        "\n",
        "        model = model_fn(**kwargs)\n",
        "\n",
        "        eval_env = env_fn(n_envs=1, eval_env=True)\n",
        "        # Account for parallel envs\n",
        "        eval_freq_ = eval_freq\n",
        "        if isinstance(model.get_env(), VecEnv):\n",
        "            eval_freq_ = max(eval_freq // model.get_env().num_envs, 1)\n",
        "        # TODO: use non-deterministic eval for Atari?\n",
        "        eval_callback = TrialEvalCallback(eval_env, trial, n_eval_episodes=n_eval_episodes,\n",
        "                                          eval_freq=eval_freq_, deterministic=True)\n",
        "\n",
        "        try:\n",
        "            model.learn(n_timesteps, callback=eval_callback)\n",
        "            # Free memory\n",
        "            model.env.close()\n",
        "            eval_env.close()\n",
        "        except AssertionError:\n",
        "            # Sometimes, random hyperparams can generate NaN\n",
        "            # Free memory\n",
        "            model.env.close()\n",
        "            eval_env.close()\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "        is_pruned = eval_callback.is_pruned\n",
        "        cost = -1 * eval_callback.last_mean_reward\n",
        "\n",
        "        del model.env, eval_env\n",
        "        del model\n",
        "\n",
        "        if is_pruned:\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        return cost\n",
        "\n",
        "    try:\n",
        "        study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    print('Number of finished trials: ', len(study.trials))\n",
        "\n",
        "    print('Best trial:')\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print('Value: ', trial.value)\n",
        "\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    return study.trials_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiquqq089Z0j"
      },
      "source": [
        "# <font color = 'blue' > 탐색 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY2jUabw4otd"
      },
      "source": [
        "# 적절한 값 입력 후 탐색\n",
        "data_frame = hyperparam_optimization(algo=args.algo, \n",
        "                                     model_fn=create_model, \n",
        "                                     env_fn=create_env, \n",
        "                                     n_trials=1000, \n",
        "                                     n_timesteps=50000 , \n",
        "                                     hyperparams=hyperparams,\n",
        "                                     n_jobs=2, \n",
        "                                     sampler_method='tpe', \n",
        "                                     pruner_method='median',\n",
        "                                     seed=0, \n",
        "                                     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj-eXeYw94_Z"
      },
      "source": [
        "# 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1z95iygbw6e"
      },
      "source": [
        "report_name = \"report_{}_{}-trials-{}-{}-{}_{}.csv\".format(env_id, args.n_trials, args.n_timesteps,\n",
        "                                                        args.sampler, args.pruner, int(time.time()))\n",
        "log_path = os.path.join(args.log_folder, args.algo, report_name)\n",
        "print(\"Writing report to {}\".format(log_path))\n",
        "\n",
        "os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
        "data_frame.to_csv(log_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ca9ibNj962W"
      },
      "source": [
        "# 결과 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPmXKxJ0lK3"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(log_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni-3DkWN-qrv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}