{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole_Dynamic_Change_A2C_Stable_Baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/stable-baselines/blob/main/CartPole_Dynamic_Change_A2C_Stable_Baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_16bQF0anmE"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCvNLM5UXza8",
        "outputId": "38388cf1-359d-44a4-e179-a81aaabb3bc3"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLsiDDX4f1tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cb2982-accf-4665-ca2c-a335becf56c7"
      },
      "source": [
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines[mpi]==2.10.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Requirement already satisfied: stable-baselines[mpi]==2.10.0 in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.18.5)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoupqggMlJ-2"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import gym"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gFKAGFh9_iW"
      },
      "source": [
        "# Custom CartPole Class 정의\n",
        "```\n",
        "    ### to replace deterministic action with stochastic action \n",
        "    #force = self.force_mag if action == 1 else -self.force_mag\n",
        "    stochastic_force = self.force_mag + np.random.normal(self.mu, self.sigma)\n",
        "    force = stochastic_force if action == 1 else -stochastic_force\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z59vDeyFS5nF"
      },
      "source": [
        "from gym.envs.classic_control import cartpole\n",
        "\n",
        "class CartPoleEnv_stochastic(cartpole.CartPoleEnv):\n",
        "\n",
        "  def __init__(self, mu, sigma):\n",
        "    super(CartPoleEnv_stochastic, self).__init__()\n",
        "    self.mu = mu\n",
        "    self.sigma = sigma\n",
        "\n",
        "  def step(self, action):\n",
        "    err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
        "    assert self.action_space.contains(action), err_msg\n",
        "\n",
        "    x, x_dot, theta, theta_dot = self.state\n",
        "    ### to replace deterministic action with stochastic action \n",
        "    #force = self.force_mag if action == 1 else -self.force_mag\n",
        "    stochastic_force = self.force_mag + np.random.normal(self.mu, self.sigma)\n",
        "    force = stochastic_force if action == 1 else -stochastic_force\n",
        "\n",
        "    costheta = math.cos(theta)\n",
        "    sintheta = math.sin(theta)\n",
        "\n",
        "    # For the interested reader:\n",
        "    # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
        "    temp = (force + self.polemass_length * theta_dot ** 2 * sintheta) / self.total_mass\n",
        "    thetaacc = (self.gravity * sintheta - costheta * temp) / (self.length * (4.0 / 3.0 - self.masspole * costheta ** 2 / self.total_mass))\n",
        "    xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
        "\n",
        "    if self.kinematics_integrator == 'euler':\n",
        "        x = x + self.tau * x_dot\n",
        "        x_dot = x_dot + self.tau * xacc\n",
        "        theta = theta + self.tau * theta_dot\n",
        "        theta_dot = theta_dot + self.tau * thetaacc\n",
        "    else:  # semi-implicit euler\n",
        "        x_dot = x_dot + self.tau * xacc\n",
        "        x = x + self.tau * x_dot\n",
        "        theta_dot = theta_dot + self.tau * thetaacc\n",
        "        theta = theta + self.tau * theta_dot\n",
        "\n",
        "    self.state = (x, x_dot, theta, theta_dot)\n",
        "\n",
        "    done = bool(\n",
        "        x < -self.x_threshold\n",
        "        or x > self.x_threshold\n",
        "        or theta < -self.theta_threshold_radians\n",
        "        or theta > self.theta_threshold_radians\n",
        "    )\n",
        "\n",
        "    if not done:\n",
        "        reward = 1.0\n",
        "    elif self.steps_beyond_done is None:\n",
        "        # Pole just fell!\n",
        "        self.steps_beyond_done = 0\n",
        "        reward = 1.0\n",
        "    else:\n",
        "        if self.steps_beyond_done == 0:\n",
        "            logger.warn(\n",
        "                \"You are calling 'step()' even though this \"\n",
        "                \"environment has already returned done = True. You \"\n",
        "                \"should always call 'reset()' once you receive 'done = \"\n",
        "                \"True' -- any further steps are undefined behavior.\"\n",
        "            )\n",
        "        self.steps_beyond_done += 1\n",
        "        reward = 0.0\n",
        "\n",
        "    return np.array(self.state), reward, done, {}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwkEaLFf-TYS"
      },
      "source": [
        "### Class 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKndjbr6YC2C",
        "outputId": "60dd725f-25c4-4a20-9194-89cb5d954519"
      },
      "source": [
        "# To check deterministic actiong\n",
        "environment = CartPoleEnv_stochastic(mu=0.0, sigma=0.0)\n",
        "for _ in range(3):\n",
        "  environment.seed(1)\n",
        "  step = environment.reset()\n",
        "  next_step = environment.step(np.array(0, dtype=np.int32))\n",
        "  print (step, '- >', next_step[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.19321569 -0.03151444  0.25146705]\n",
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.19321569 -0.03151444  0.25146705]\n",
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.19321569 -0.03151444  0.25146705]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBGJKF89YDZ8",
        "outputId": "760d56d5-3bfe-4ca4-a4ba-f2bb50f3db8f"
      },
      "source": [
        "# To check stochastic action\n",
        "environment = CartPoleEnv_stochastic(mu=0.0, sigma=0.5)\n",
        "for _ in range(3):\n",
        "  environment.seed(1)\n",
        "  step = environment.reset()\n",
        "  next_step = environment.step(np.array(0, dtype=np.int32))\n",
        "  print (step, '- >', next_step[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.18783056 -0.03151444  0.24339321]\n",
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.1955017  -0.03151444  0.25489444]\n",
            "[ 0.03073904  0.00145001 -0.03088818 -0.03131252] - > [ 0.03076804 -0.19513888 -0.03151444  0.25435046]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7zx0cYq-Wit"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKpeHZ4EtUDf"
      },
      "source": [
        "def TimeLimit(env):\n",
        "  return gym.wrappers.TimeLimit(env, max_episode_steps=500)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwK7vUXYC5b"
      },
      "source": [
        "from stable_baselines.common import make_vec_env\n",
        "\n",
        "env = make_vec_env(CartPoleEnv_stochastic, \n",
        "                   n_envs=4, \n",
        "                   seed=1000,\n",
        "                   wrapper_class=TimeLimit, \n",
        "                   env_kwargs={'mu':0., \"sigma\":0.5})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wc65vEnYDci"
      },
      "source": [
        "# Same as before we instantiate the agent along with the environment\n",
        "from stable_baselines import A2C\n",
        "\n",
        "a2c_model = A2C('MlpPolicy', env, tensorboard_log='./log', verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8IaS_-0YDuy",
        "outputId": "27605fb0-5af5-4ba7-dfc0-f4ccaf9c4ecc"
      },
      "source": [
        "# Train the agent for 10000 steps\n",
        "a2c_model.learn(total_timesteps=1000000, log_interval=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "---------------------------------\n",
            "| ep_len_mean        | 23.2     |\n",
            "| ep_reward_mean     | 23.2     |\n",
            "| explained_variance | 0.0288   |\n",
            "| fps                | 2030     |\n",
            "| nupdates           | 100      |\n",
            "| policy_entropy     | 0.693    |\n",
            "| total_timesteps    | 2000     |\n",
            "| value_loss         | 9.86     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 23.6     |\n",
            "| ep_reward_mean     | 23.6     |\n",
            "| explained_variance | -0.043   |\n",
            "| fps                | 2290     |\n",
            "| nupdates           | 200      |\n",
            "| policy_entropy     | 0.693    |\n",
            "| total_timesteps    | 4000     |\n",
            "| value_loss         | 7.5      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 22.5     |\n",
            "| ep_reward_mean     | 22.5     |\n",
            "| explained_variance | 0.152    |\n",
            "| fps                | 2410     |\n",
            "| nupdates           | 300      |\n",
            "| policy_entropy     | 0.693    |\n",
            "| total_timesteps    | 6000     |\n",
            "| value_loss         | 10.1     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 20.2     |\n",
            "| ep_reward_mean     | 20.2     |\n",
            "| explained_variance | 0.0883   |\n",
            "| fps                | 2471     |\n",
            "| nupdates           | 400      |\n",
            "| policy_entropy     | 0.693    |\n",
            "| total_timesteps    | 8000     |\n",
            "| value_loss         | 8.76     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 24.6     |\n",
            "| ep_reward_mean     | 24.6     |\n",
            "| explained_variance | -0.0212  |\n",
            "| fps                | 2485     |\n",
            "| nupdates           | 500      |\n",
            "| policy_entropy     | 0.693    |\n",
            "| total_timesteps    | 10000    |\n",
            "| value_loss         | 8.02     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 26       |\n",
            "| ep_reward_mean     | 26       |\n",
            "| explained_variance | -0.159   |\n",
            "| fps                | 2502     |\n",
            "| nupdates           | 600      |\n",
            "| policy_entropy     | 0.692    |\n",
            "| total_timesteps    | 12000    |\n",
            "| value_loss         | 11.5     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 28.4     |\n",
            "| ep_reward_mean     | 28.4     |\n",
            "| explained_variance | 0.165    |\n",
            "| fps                | 2514     |\n",
            "| nupdates           | 700      |\n",
            "| policy_entropy     | 0.689    |\n",
            "| total_timesteps    | 14000    |\n",
            "| value_loss         | 5.96     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 28.2     |\n",
            "| ep_reward_mean     | 28.2     |\n",
            "| explained_variance | 0.0894   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 800      |\n",
            "| policy_entropy     | 0.684    |\n",
            "| total_timesteps    | 16000    |\n",
            "| value_loss         | 9.32     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 31.2     |\n",
            "| ep_reward_mean     | 31.2     |\n",
            "| explained_variance | 0.0885   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 900      |\n",
            "| policy_entropy     | 0.654    |\n",
            "| total_timesteps    | 18000    |\n",
            "| value_loss         | 36.7     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 36.8     |\n",
            "| ep_reward_mean     | 36.8     |\n",
            "| explained_variance | 0.228    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 1000     |\n",
            "| policy_entropy     | 0.641    |\n",
            "| total_timesteps    | 20000    |\n",
            "| value_loss         | 5.64     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 42.3     |\n",
            "| ep_reward_mean     | 42.3     |\n",
            "| explained_variance | 0.173    |\n",
            "| fps                | 2552     |\n",
            "| nupdates           | 1100     |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 22000    |\n",
            "| value_loss         | 6.12     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 47       |\n",
            "| ep_reward_mean     | 47       |\n",
            "| explained_variance | 0.0135   |\n",
            "| fps                | 2560     |\n",
            "| nupdates           | 1200     |\n",
            "| policy_entropy     | 0.633    |\n",
            "| total_timesteps    | 24000    |\n",
            "| value_loss         | 116      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 54.3     |\n",
            "| ep_reward_mean     | 54.3     |\n",
            "| explained_variance | 0.0221   |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 1300     |\n",
            "| policy_entropy     | 0.655    |\n",
            "| total_timesteps    | 26000    |\n",
            "| value_loss         | 142      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 58.8     |\n",
            "| ep_reward_mean     | 58.8     |\n",
            "| explained_variance | 0.0395   |\n",
            "| fps                | 2570     |\n",
            "| nupdates           | 1400     |\n",
            "| policy_entropy     | 0.624    |\n",
            "| total_timesteps    | 28000    |\n",
            "| value_loss         | 4.78     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 70.3     |\n",
            "| ep_reward_mean     | 70.3     |\n",
            "| explained_variance | 0.0122   |\n",
            "| fps                | 2576     |\n",
            "| nupdates           | 1500     |\n",
            "| policy_entropy     | 0.607    |\n",
            "| total_timesteps    | 30000    |\n",
            "| value_loss         | 270      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 76.8     |\n",
            "| ep_reward_mean     | 76.8     |\n",
            "| explained_variance | 0.0136   |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 1600     |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 32000    |\n",
            "| value_loss         | 3.98     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 82.7     |\n",
            "| ep_reward_mean     | 82.7     |\n",
            "| explained_variance | -0.0111  |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 1700     |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 34000    |\n",
            "| value_loss         | 3.61     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 90.2     |\n",
            "| ep_reward_mean     | 90.2     |\n",
            "| explained_variance | 0.00718  |\n",
            "| fps                | 2582     |\n",
            "| nupdates           | 1800     |\n",
            "| policy_entropy     | 0.606    |\n",
            "| total_timesteps    | 36000    |\n",
            "| value_loss         | 3.16     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 99.2     |\n",
            "| ep_reward_mean     | 99.2     |\n",
            "| explained_variance | 0.00824  |\n",
            "| fps                | 2584     |\n",
            "| nupdates           | 1900     |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 38000    |\n",
            "| value_loss         | 2.79     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 108      |\n",
            "| ep_reward_mean     | 108      |\n",
            "| explained_variance | -0.00189 |\n",
            "| fps                | 2588     |\n",
            "| nupdates           | 2000     |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 40000    |\n",
            "| value_loss         | 2.42     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 114      |\n",
            "| ep_reward_mean     | 114      |\n",
            "| explained_variance | 0.0048   |\n",
            "| fps                | 2586     |\n",
            "| nupdates           | 2100     |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 42000    |\n",
            "| value_loss         | 2.04     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 127      |\n",
            "| ep_reward_mean     | 127      |\n",
            "| explained_variance | 0.00227  |\n",
            "| fps                | 2568     |\n",
            "| nupdates           | 2200     |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 44000    |\n",
            "| value_loss         | 1.71     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 139      |\n",
            "| ep_reward_mean     | 139      |\n",
            "| explained_variance | 0.00263  |\n",
            "| fps                | 2555     |\n",
            "| nupdates           | 2300     |\n",
            "| policy_entropy     | 0.595    |\n",
            "| total_timesteps    | 46000    |\n",
            "| value_loss         | 745      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 147      |\n",
            "| ep_reward_mean     | 147      |\n",
            "| explained_variance | 0.00236  |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 2400     |\n",
            "| policy_entropy     | 0.603    |\n",
            "| total_timesteps    | 48000    |\n",
            "| value_loss         | 1.14     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 158      |\n",
            "| ep_reward_mean     | 158      |\n",
            "| explained_variance | -0.00229 |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 2500     |\n",
            "| policy_entropy     | 0.532    |\n",
            "| total_timesteps    | 50000    |\n",
            "| value_loss         | 0.899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 167      |\n",
            "| ep_reward_mean     | 167      |\n",
            "| explained_variance | 0.000268 |\n",
            "| fps                | 2514     |\n",
            "| nupdates           | 2600     |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 52000    |\n",
            "| value_loss         | 791      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 173      |\n",
            "| ep_reward_mean     | 173      |\n",
            "| explained_variance | -0.00112 |\n",
            "| fps                | 2505     |\n",
            "| nupdates           | 2700     |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 54000    |\n",
            "| value_loss         | 0.519    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 171      |\n",
            "| ep_reward_mean     | 171      |\n",
            "| explained_variance | 0.00782  |\n",
            "| fps                | 2493     |\n",
            "| nupdates           | 2800     |\n",
            "| policy_entropy     | 0.615    |\n",
            "| total_timesteps    | 56000    |\n",
            "| value_loss         | 0.354    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 174      |\n",
            "| ep_reward_mean     | 174      |\n",
            "| explained_variance | 0.0167   |\n",
            "| fps                | 2483     |\n",
            "| nupdates           | 2900     |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 58000    |\n",
            "| value_loss         | 0.227    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 182      |\n",
            "| ep_reward_mean     | 182      |\n",
            "| explained_variance | 0.000182 |\n",
            "| fps                | 2477     |\n",
            "| nupdates           | 3000     |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 60000    |\n",
            "| value_loss         | 0.129    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 179      |\n",
            "| ep_reward_mean     | 179      |\n",
            "| explained_variance | -0.00015 |\n",
            "| fps                | 2471     |\n",
            "| nupdates           | 3100     |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 62000    |\n",
            "| value_loss         | 1.64e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 182      |\n",
            "| ep_reward_mean     | 182      |\n",
            "| explained_variance | -0.00602 |\n",
            "| fps                | 2469     |\n",
            "| nupdates           | 3200     |\n",
            "| policy_entropy     | 0.581    |\n",
            "| total_timesteps    | 64000    |\n",
            "| value_loss         | 0.0131   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 186      |\n",
            "| ep_reward_mean     | 186      |\n",
            "| explained_variance | 0.0365   |\n",
            "| fps                | 2463     |\n",
            "| nupdates           | 3300     |\n",
            "| policy_entropy     | 0.468    |\n",
            "| total_timesteps    | 66000    |\n",
            "| value_loss         | 0.00216  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 189      |\n",
            "| ep_reward_mean     | 189      |\n",
            "| explained_variance | 0.886    |\n",
            "| fps                | 2469     |\n",
            "| nupdates           | 3400     |\n",
            "| policy_entropy     | 0.576    |\n",
            "| total_timesteps    | 68000    |\n",
            "| value_loss         | 0.000265 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 191      |\n",
            "| ep_reward_mean     | 191      |\n",
            "| explained_variance | 0.761    |\n",
            "| fps                | 2475     |\n",
            "| nupdates           | 3500     |\n",
            "| policy_entropy     | 0.582    |\n",
            "| total_timesteps    | 70000    |\n",
            "| value_loss         | 0.000143 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 196      |\n",
            "| ep_reward_mean     | 196      |\n",
            "| explained_variance | 0.733    |\n",
            "| fps                | 2481     |\n",
            "| nupdates           | 3600     |\n",
            "| policy_entropy     | 0.514    |\n",
            "| total_timesteps    | 72000    |\n",
            "| value_loss         | 7.46e-05 |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 205       |\n",
            "| ep_reward_mean     | 205       |\n",
            "| explained_variance | -0.000954 |\n",
            "| fps                | 2484      |\n",
            "| nupdates           | 3700      |\n",
            "| policy_entropy     | 0.618     |\n",
            "| total_timesteps    | 74000     |\n",
            "| value_loss         | 486       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 205      |\n",
            "| ep_reward_mean     | 205      |\n",
            "| explained_variance | 0.702    |\n",
            "| fps                | 2487     |\n",
            "| nupdates           | 3800     |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 76000    |\n",
            "| value_loss         | 0.000323 |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 183       |\n",
            "| ep_reward_mean     | 183       |\n",
            "| explained_variance | -0.000229 |\n",
            "| fps                | 2489      |\n",
            "| nupdates           | 3900      |\n",
            "| policy_entropy     | 0.547     |\n",
            "| total_timesteps    | 78000     |\n",
            "| value_loss         | 2.29e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 157      |\n",
            "| explained_variance | 0.95     |\n",
            "| fps                | 2494     |\n",
            "| nupdates           | 4000     |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 80000    |\n",
            "| value_loss         | 0.734    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 78.1     |\n",
            "| ep_reward_mean     | 78.1     |\n",
            "| explained_variance | 0.0116   |\n",
            "| fps                | 2496     |\n",
            "| nupdates           | 4100     |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 82000    |\n",
            "| value_loss         | 440      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 57.5     |\n",
            "| ep_reward_mean     | 57.5     |\n",
            "| explained_variance | 0.986    |\n",
            "| fps                | 2499     |\n",
            "| nupdates           | 4200     |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 84000    |\n",
            "| value_loss         | 3.3      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 56.4     |\n",
            "| ep_reward_mean     | 56.4     |\n",
            "| explained_variance | 0.988    |\n",
            "| fps                | 2503     |\n",
            "| nupdates           | 4300     |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 86000    |\n",
            "| value_loss         | 8.69     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 62.6     |\n",
            "| ep_reward_mean     | 62.6     |\n",
            "| explained_variance | 0.996    |\n",
            "| fps                | 2508     |\n",
            "| nupdates           | 4400     |\n",
            "| policy_entropy     | 0.55     |\n",
            "| total_timesteps    | 88000    |\n",
            "| value_loss         | 8.17     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 71.5     |\n",
            "| ep_reward_mean     | 71.5     |\n",
            "| explained_variance | 0.997    |\n",
            "| fps                | 2511     |\n",
            "| nupdates           | 4500     |\n",
            "| policy_entropy     | 0.499    |\n",
            "| total_timesteps    | 90000    |\n",
            "| value_loss         | 3.39     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 77.7     |\n",
            "| ep_reward_mean     | 77.7     |\n",
            "| explained_variance | 0.979    |\n",
            "| fps                | 2514     |\n",
            "| nupdates           | 4600     |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 92000    |\n",
            "| value_loss         | 1.46     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 77.8     |\n",
            "| ep_reward_mean     | 77.8     |\n",
            "| explained_variance | -0.0366  |\n",
            "| fps                | 2517     |\n",
            "| nupdates           | 4700     |\n",
            "| policy_entropy     | 0.506    |\n",
            "| total_timesteps    | 94000    |\n",
            "| value_loss         | 3.81e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 67.9     |\n",
            "| ep_reward_mean     | 67.9     |\n",
            "| explained_variance | -0.00953 |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 4800     |\n",
            "| policy_entropy     | 0.517    |\n",
            "| total_timesteps    | 96000    |\n",
            "| value_loss         | 458      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 63.1     |\n",
            "| ep_reward_mean     | 63.1     |\n",
            "| explained_variance | 0.817    |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 4900     |\n",
            "| policy_entropy     | 0.513    |\n",
            "| total_timesteps    | 98000    |\n",
            "| value_loss         | 0.00304  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 66       |\n",
            "| ep_reward_mean     | 66       |\n",
            "| explained_variance | 0.943    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 5000     |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 100000   |\n",
            "| value_loss         | 0.00826  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 74.3     |\n",
            "| ep_reward_mean     | 74.3     |\n",
            "| explained_variance | 0.837    |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 5100     |\n",
            "| policy_entropy     | 0.599    |\n",
            "| total_timesteps    | 102000   |\n",
            "| value_loss         | 0.000749 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 86.8     |\n",
            "| ep_reward_mean     | 86.8     |\n",
            "| explained_variance | 0.742    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 5200     |\n",
            "| policy_entropy     | 0.597    |\n",
            "| total_timesteps    | 104000   |\n",
            "| value_loss         | 0.000117 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 97.7     |\n",
            "| ep_reward_mean     | 97.7     |\n",
            "| explained_variance | 0.744    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 5300     |\n",
            "| policy_entropy     | 0.585    |\n",
            "| total_timesteps    | 106000   |\n",
            "| value_loss         | 0.00417  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 104      |\n",
            "| ep_reward_mean     | 104      |\n",
            "| explained_variance | 0.943    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 5400     |\n",
            "| policy_entropy     | 0.542    |\n",
            "| total_timesteps    | 108000   |\n",
            "| value_loss         | 0.0031   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 98.8     |\n",
            "| ep_reward_mean     | 98.8     |\n",
            "| explained_variance | 0.175    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 5500     |\n",
            "| policy_entropy     | 0.63     |\n",
            "| total_timesteps    | 110000   |\n",
            "| value_loss         | 0.000889 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 96.7     |\n",
            "| ep_reward_mean     | 96.7     |\n",
            "| explained_variance | 0.728    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 5600     |\n",
            "| policy_entropy     | 0.585    |\n",
            "| total_timesteps    | 112000   |\n",
            "| value_loss         | 0.00434  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 95.7     |\n",
            "| ep_reward_mean     | 95.7     |\n",
            "| explained_variance | 0.395    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 5700     |\n",
            "| policy_entropy     | 0.636    |\n",
            "| total_timesteps    | 114000   |\n",
            "| value_loss         | 0.000132 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 92.8     |\n",
            "| ep_reward_mean     | 92.8     |\n",
            "| explained_variance | 0.834    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 5800     |\n",
            "| policy_entropy     | 0.645    |\n",
            "| total_timesteps    | 116000   |\n",
            "| value_loss         | 0.00109  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 97.9      |\n",
            "| ep_reward_mean     | 97.9      |\n",
            "| explained_variance | -0.000373 |\n",
            "| fps                | 2545      |\n",
            "| nupdates           | 5900      |\n",
            "| policy_entropy     | 0.631     |\n",
            "| total_timesteps    | 118000    |\n",
            "| value_loss         | 2.33e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 97.9     |\n",
            "| ep_reward_mean     | 97.9     |\n",
            "| explained_variance | 0.342    |\n",
            "| fps                | 2545     |\n",
            "| nupdates           | 6000     |\n",
            "| policy_entropy     | 0.565    |\n",
            "| total_timesteps    | 120000   |\n",
            "| value_loss         | 0.00394  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 93.4     |\n",
            "| ep_reward_mean     | 93.4     |\n",
            "| explained_variance | 0.705    |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 6100     |\n",
            "| policy_entropy     | 0.645    |\n",
            "| total_timesteps    | 122000   |\n",
            "| value_loss         | 0.000919 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 94.6     |\n",
            "| ep_reward_mean     | 94.6     |\n",
            "| explained_variance | 0.377    |\n",
            "| fps                | 2548     |\n",
            "| nupdates           | 6200     |\n",
            "| policy_entropy     | 0.599    |\n",
            "| total_timesteps    | 124000   |\n",
            "| value_loss         | 0.000123 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 105      |\n",
            "| ep_reward_mean     | 105      |\n",
            "| explained_variance | 0.604    |\n",
            "| fps                | 2550     |\n",
            "| nupdates           | 6300     |\n",
            "| policy_entropy     | 0.514    |\n",
            "| total_timesteps    | 126000   |\n",
            "| value_loss         | 0.00065  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 109      |\n",
            "| ep_reward_mean     | 109      |\n",
            "| explained_variance | 0.642    |\n",
            "| fps                | 2549     |\n",
            "| nupdates           | 6400     |\n",
            "| policy_entropy     | 0.647    |\n",
            "| total_timesteps    | 128000   |\n",
            "| value_loss         | 0.000184 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 116      |\n",
            "| ep_reward_mean     | 116      |\n",
            "| explained_variance | 0.855    |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 6500     |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 130000   |\n",
            "| value_loss         | 0.00198  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 119      |\n",
            "| ep_reward_mean     | 119      |\n",
            "| explained_variance | 0.514    |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 6600     |\n",
            "| policy_entropy     | 0.568    |\n",
            "| total_timesteps    | 132000   |\n",
            "| value_loss         | 0.00163  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 119      |\n",
            "| ep_reward_mean     | 119      |\n",
            "| explained_variance | 0.484    |\n",
            "| fps                | 2549     |\n",
            "| nupdates           | 6700     |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 134000   |\n",
            "| value_loss         | 0.00236  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 108      |\n",
            "| ep_reward_mean     | 108      |\n",
            "| explained_variance | 0.823    |\n",
            "| fps                | 2550     |\n",
            "| nupdates           | 6800     |\n",
            "| policy_entropy     | 0.622    |\n",
            "| total_timesteps    | 136000   |\n",
            "| value_loss         | 0.00148  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 102      |\n",
            "| ep_reward_mean     | 102      |\n",
            "| explained_variance | 0.464    |\n",
            "| fps                | 2552     |\n",
            "| nupdates           | 6900     |\n",
            "| policy_entropy     | 0.622    |\n",
            "| total_timesteps    | 138000   |\n",
            "| value_loss         | 0.000288 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 99.4     |\n",
            "| ep_reward_mean     | 99.4     |\n",
            "| explained_variance | 0.176    |\n",
            "| fps                | 2552     |\n",
            "| nupdates           | 7000     |\n",
            "| policy_entropy     | 0.57     |\n",
            "| total_timesteps    | 140000   |\n",
            "| value_loss         | 0.000403 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 104      |\n",
            "| ep_reward_mean     | 104      |\n",
            "| explained_variance | -0.00801 |\n",
            "| fps                | 2554     |\n",
            "| nupdates           | 7100     |\n",
            "| policy_entropy     | 0.566    |\n",
            "| total_timesteps    | 142000   |\n",
            "| value_loss         | 0.000603 |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 102       |\n",
            "| ep_reward_mean     | 102       |\n",
            "| explained_variance | -0.000484 |\n",
            "| fps                | 2556      |\n",
            "| nupdates           | 7200      |\n",
            "| policy_entropy     | 0.54      |\n",
            "| total_timesteps    | 144000    |\n",
            "| value_loss         | 1.86e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 103      |\n",
            "| ep_reward_mean     | 103      |\n",
            "| explained_variance | 0.171    |\n",
            "| fps                | 2557     |\n",
            "| nupdates           | 7300     |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 146000   |\n",
            "| value_loss         | 0.00179  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 94        |\n",
            "| ep_reward_mean     | 94        |\n",
            "| explained_variance | -0.000629 |\n",
            "| fps                | 2557      |\n",
            "| nupdates           | 7400      |\n",
            "| policy_entropy     | 0.595     |\n",
            "| total_timesteps    | 148000    |\n",
            "| value_loss         | 1.86e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 81.3     |\n",
            "| ep_reward_mean     | 81.3     |\n",
            "| explained_variance | 0.096    |\n",
            "| fps                | 2559     |\n",
            "| nupdates           | 7500     |\n",
            "| policy_entropy     | 0.639    |\n",
            "| total_timesteps    | 150000   |\n",
            "| value_loss         | 0.00197  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 84.8     |\n",
            "| ep_reward_mean     | 84.8     |\n",
            "| explained_variance | -0.0362  |\n",
            "| fps                | 2559     |\n",
            "| nupdates           | 7600     |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 152000   |\n",
            "| value_loss         | 0.000665 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 87       |\n",
            "| ep_reward_mean     | 87       |\n",
            "| explained_variance | 0.48     |\n",
            "| fps                | 2561     |\n",
            "| nupdates           | 7700     |\n",
            "| policy_entropy     | 0.606    |\n",
            "| total_timesteps    | 154000   |\n",
            "| value_loss         | 0.000163 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 96.6     |\n",
            "| ep_reward_mean     | 96.6     |\n",
            "| explained_variance | 0.88     |\n",
            "| fps                | 2561     |\n",
            "| nupdates           | 7800     |\n",
            "| policy_entropy     | 0.607    |\n",
            "| total_timesteps    | 156000   |\n",
            "| value_loss         | 0.000549 |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 104       |\n",
            "| ep_reward_mean     | 104       |\n",
            "| explained_variance | -0.000204 |\n",
            "| fps                | 2562      |\n",
            "| nupdates           | 7900      |\n",
            "| policy_entropy     | 0.565     |\n",
            "| total_timesteps    | 158000    |\n",
            "| value_loss         | 1.88e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 111      |\n",
            "| ep_reward_mean     | 111      |\n",
            "| explained_variance | -0.0353  |\n",
            "| fps                | 2563     |\n",
            "| nupdates           | 8000     |\n",
            "| policy_entropy     | 0.618    |\n",
            "| total_timesteps    | 160000   |\n",
            "| value_loss         | 0.000203 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 123      |\n",
            "| ep_reward_mean     | 123      |\n",
            "| explained_variance | 0.844    |\n",
            "| fps                | 2564     |\n",
            "| nupdates           | 8100     |\n",
            "| policy_entropy     | 0.585    |\n",
            "| total_timesteps    | 162000   |\n",
            "| value_loss         | 0.000101 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 133      |\n",
            "| ep_reward_mean     | 133      |\n",
            "| explained_variance | 0.829    |\n",
            "| fps                | 2566     |\n",
            "| nupdates           | 8200     |\n",
            "| policy_entropy     | 0.635    |\n",
            "| total_timesteps    | 164000   |\n",
            "| value_loss         | 0.000108 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | 146      |\n",
            "| explained_variance | 0.947    |\n",
            "| fps                | 2567     |\n",
            "| nupdates           | 8300     |\n",
            "| policy_entropy     | 0.62     |\n",
            "| total_timesteps    | 166000   |\n",
            "| value_loss         | 0.000115 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 153      |\n",
            "| explained_variance | 0.971    |\n",
            "| fps                | 2567     |\n",
            "| nupdates           | 8400     |\n",
            "| policy_entropy     | 0.635    |\n",
            "| total_timesteps    | 168000   |\n",
            "| value_loss         | 9.46e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 163      |\n",
            "| ep_reward_mean     | 163      |\n",
            "| explained_variance | 0.423    |\n",
            "| fps                | 2568     |\n",
            "| nupdates           | 8500     |\n",
            "| policy_entropy     | 0.586    |\n",
            "| total_timesteps    | 170000   |\n",
            "| value_loss         | 0.000176 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 169      |\n",
            "| ep_reward_mean     | 169      |\n",
            "| explained_variance | 0.656    |\n",
            "| fps                | 2569     |\n",
            "| nupdates           | 8600     |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 172000   |\n",
            "| value_loss         | 0.000146 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 172      |\n",
            "| ep_reward_mean     | 172      |\n",
            "| explained_variance | 0.435    |\n",
            "| fps                | 2569     |\n",
            "| nupdates           | 8700     |\n",
            "| policy_entropy     | 0.545    |\n",
            "| total_timesteps    | 174000   |\n",
            "| value_loss         | 0.000112 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 172      |\n",
            "| ep_reward_mean     | 172      |\n",
            "| explained_variance | 0.334    |\n",
            "| fps                | 2569     |\n",
            "| nupdates           | 8800     |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 176000   |\n",
            "| value_loss         | 0.000127 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 173      |\n",
            "| ep_reward_mean     | 173      |\n",
            "| explained_variance | 0.279    |\n",
            "| fps                | 2569     |\n",
            "| nupdates           | 8900     |\n",
            "| policy_entropy     | 0.573    |\n",
            "| total_timesteps    | 178000   |\n",
            "| value_loss         | 9.12e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 174      |\n",
            "| ep_reward_mean     | 174      |\n",
            "| explained_variance | 0.506    |\n",
            "| fps                | 2570     |\n",
            "| nupdates           | 9000     |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 180000   |\n",
            "| value_loss         | 9.17e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 150      |\n",
            "| explained_variance | 0.829    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 9100     |\n",
            "| policy_entropy     | 0.603    |\n",
            "| total_timesteps    | 182000   |\n",
            "| value_loss         | 0.00123  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 138      |\n",
            "| ep_reward_mean     | 138      |\n",
            "| explained_variance | 0.893    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 9200     |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 184000   |\n",
            "| value_loss         | 0.000336 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 136      |\n",
            "| ep_reward_mean     | 136      |\n",
            "| explained_variance | 0.897    |\n",
            "| fps                | 2572     |\n",
            "| nupdates           | 9300     |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 186000   |\n",
            "| value_loss         | 0.00023  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 138      |\n",
            "| ep_reward_mean     | 138      |\n",
            "| explained_variance | 0.592    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 9400     |\n",
            "| policy_entropy     | 0.522    |\n",
            "| total_timesteps    | 188000   |\n",
            "| value_loss         | 0.000418 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 147      |\n",
            "| ep_reward_mean     | 147      |\n",
            "| explained_variance | 0.916    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 9500     |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 190000   |\n",
            "| value_loss         | 0.000111 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 154      |\n",
            "| explained_variance | 0.786    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 9600     |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 192000   |\n",
            "| value_loss         | 0.000296 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 150      |\n",
            "| explained_variance | 0.125    |\n",
            "| fps                | 2572     |\n",
            "| nupdates           | 9700     |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 194000   |\n",
            "| value_loss         | 0.000287 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 153      |\n",
            "| ep_reward_mean     | 153      |\n",
            "| explained_variance | -0.324   |\n",
            "| fps                | 2573     |\n",
            "| nupdates           | 9800     |\n",
            "| policy_entropy     | 0.598    |\n",
            "| total_timesteps    | 196000   |\n",
            "| value_loss         | 0.000374 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 157      |\n",
            "| explained_variance | 0.326    |\n",
            "| fps                | 2574     |\n",
            "| nupdates           | 9900     |\n",
            "| policy_entropy     | 0.645    |\n",
            "| total_timesteps    | 198000   |\n",
            "| value_loss         | 0.000264 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 154      |\n",
            "| ep_reward_mean     | 154      |\n",
            "| explained_variance | 0.235    |\n",
            "| fps                | 2574     |\n",
            "| nupdates           | 10000    |\n",
            "| policy_entropy     | 0.532    |\n",
            "| total_timesteps    | 200000   |\n",
            "| value_loss         | 0.000464 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 150      |\n",
            "| ep_reward_mean     | 150      |\n",
            "| explained_variance | 0.884    |\n",
            "| fps                | 2575     |\n",
            "| nupdates           | 10100    |\n",
            "| policy_entropy     | 0.671    |\n",
            "| total_timesteps    | 202000   |\n",
            "| value_loss         | 0.000316 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 143      |\n",
            "| ep_reward_mean     | 143      |\n",
            "| explained_variance | 0.873    |\n",
            "| fps                | 2575     |\n",
            "| nupdates           | 10200    |\n",
            "| policy_entropy     | 0.627    |\n",
            "| total_timesteps    | 204000   |\n",
            "| value_loss         | 0.000131 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 140      |\n",
            "| ep_reward_mean     | 140      |\n",
            "| explained_variance | 0.2      |\n",
            "| fps                | 2576     |\n",
            "| nupdates           | 10300    |\n",
            "| policy_entropy     | 0.511    |\n",
            "| total_timesteps    | 206000   |\n",
            "| value_loss         | 0.000569 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 144      |\n",
            "| ep_reward_mean     | 144      |\n",
            "| explained_variance | 0.0398   |\n",
            "| fps                | 2576     |\n",
            "| nupdates           | 10400    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 208000   |\n",
            "| value_loss         | 0.000336 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 142      |\n",
            "| ep_reward_mean     | 142      |\n",
            "| explained_variance | 0.693    |\n",
            "| fps                | 2577     |\n",
            "| nupdates           | 10500    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 210000   |\n",
            "| value_loss         | 0.000102 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 146      |\n",
            "| ep_reward_mean     | 146      |\n",
            "| explained_variance | 0.000998 |\n",
            "| fps                | 2577     |\n",
            "| nupdates           | 10600    |\n",
            "| policy_entropy     | 0.629    |\n",
            "| total_timesteps    | 212000   |\n",
            "| value_loss         | 966      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 157      |\n",
            "| ep_reward_mean     | 157      |\n",
            "| explained_variance | 0.522    |\n",
            "| fps                | 2577     |\n",
            "| nupdates           | 10700    |\n",
            "| policy_entropy     | 0.576    |\n",
            "| total_timesteps    | 214000   |\n",
            "| value_loss         | 0.00045  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 165      |\n",
            "| ep_reward_mean     | 165      |\n",
            "| explained_variance | 0.827    |\n",
            "| fps                | 2578     |\n",
            "| nupdates           | 10800    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 216000   |\n",
            "| value_loss         | 7.98e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 174      |\n",
            "| ep_reward_mean     | 174      |\n",
            "| explained_variance | 0.987    |\n",
            "| fps                | 2578     |\n",
            "| nupdates           | 10900    |\n",
            "| policy_entropy     | 0.613    |\n",
            "| total_timesteps    | 218000   |\n",
            "| value_loss         | 0.000111 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 180      |\n",
            "| ep_reward_mean     | 180      |\n",
            "| explained_variance | 0.889    |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 11000    |\n",
            "| policy_entropy     | 0.573    |\n",
            "| total_timesteps    | 220000   |\n",
            "| value_loss         | 0.00117  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 167      |\n",
            "| ep_reward_mean     | 167      |\n",
            "| explained_variance | 0.997    |\n",
            "| fps                | 2577     |\n",
            "| nupdates           | 11100    |\n",
            "| policy_entropy     | 0.591    |\n",
            "| total_timesteps    | 222000   |\n",
            "| value_loss         | 0.0271   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 168      |\n",
            "| ep_reward_mean     | 168      |\n",
            "| explained_variance | 0.947    |\n",
            "| fps                | 2578     |\n",
            "| nupdates           | 11200    |\n",
            "| policy_entropy     | 0.586    |\n",
            "| total_timesteps    | 224000   |\n",
            "| value_loss         | 0.00106  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 174      |\n",
            "| ep_reward_mean     | 174      |\n",
            "| explained_variance | 0.985    |\n",
            "| fps                | 2577     |\n",
            "| nupdates           | 11300    |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 226000   |\n",
            "| value_loss         | 0.00439  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 177      |\n",
            "| ep_reward_mean     | 177      |\n",
            "| explained_variance | 0.747    |\n",
            "| fps                | 2578     |\n",
            "| nupdates           | 11400    |\n",
            "| policy_entropy     | 0.527    |\n",
            "| total_timesteps    | 228000   |\n",
            "| value_loss         | 0.00154  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 179      |\n",
            "| ep_reward_mean     | 179      |\n",
            "| explained_variance | 0.00268  |\n",
            "| fps                | 2578     |\n",
            "| nupdates           | 11500    |\n",
            "| policy_entropy     | 0.556    |\n",
            "| total_timesteps    | 230000   |\n",
            "| value_loss         | 2.33e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 177      |\n",
            "| ep_reward_mean     | 177      |\n",
            "| explained_variance | 0.367    |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 11600    |\n",
            "| policy_entropy     | 0.629    |\n",
            "| total_timesteps    | 232000   |\n",
            "| value_loss         | 0.000111 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 179      |\n",
            "| ep_reward_mean     | 179      |\n",
            "| explained_variance | 0.695    |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 11700    |\n",
            "| policy_entropy     | 0.595    |\n",
            "| total_timesteps    | 234000   |\n",
            "| value_loss         | 0.000359 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 179      |\n",
            "| ep_reward_mean     | 179      |\n",
            "| explained_variance | -0.252   |\n",
            "| fps                | 2579     |\n",
            "| nupdates           | 11800    |\n",
            "| policy_entropy     | 0.621    |\n",
            "| total_timesteps    | 236000   |\n",
            "| value_loss         | 0.0002   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 182      |\n",
            "| ep_reward_mean     | 182      |\n",
            "| explained_variance | 0.086    |\n",
            "| fps                | 2580     |\n",
            "| nupdates           | 11900    |\n",
            "| policy_entropy     | 0.536    |\n",
            "| total_timesteps    | 238000   |\n",
            "| value_loss         | 0.000388 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 176      |\n",
            "| ep_reward_mean     | 176      |\n",
            "| explained_variance | -1.14    |\n",
            "| fps                | 2581     |\n",
            "| nupdates           | 12000    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 240000   |\n",
            "| value_loss         | 0.00199  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 172      |\n",
            "| ep_reward_mean     | 172      |\n",
            "| explained_variance | 0.00751  |\n",
            "| fps                | 2580     |\n",
            "| nupdates           | 12100    |\n",
            "| policy_entropy     | 0.48     |\n",
            "| total_timesteps    | 242000   |\n",
            "| value_loss         | 0.000706 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 167      |\n",
            "| ep_reward_mean     | 167      |\n",
            "| explained_variance | 0.67     |\n",
            "| fps                | 2581     |\n",
            "| nupdates           | 12200    |\n",
            "| policy_entropy     | 0.487    |\n",
            "| total_timesteps    | 244000   |\n",
            "| value_loss         | 0.00038  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 172      |\n",
            "| ep_reward_mean     | 172      |\n",
            "| explained_variance | 0.863    |\n",
            "| fps                | 2581     |\n",
            "| nupdates           | 12300    |\n",
            "| policy_entropy     | 0.586    |\n",
            "| total_timesteps    | 246000   |\n",
            "| value_loss         | 0.000381 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 175      |\n",
            "| ep_reward_mean     | 175      |\n",
            "| explained_variance | 0.915    |\n",
            "| fps                | 2582     |\n",
            "| nupdates           | 12400    |\n",
            "| policy_entropy     | 0.419    |\n",
            "| total_timesteps    | 248000   |\n",
            "| value_loss         | 0.000311 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 181      |\n",
            "| ep_reward_mean     | 181      |\n",
            "| explained_variance | 0.66     |\n",
            "| fps                | 2582     |\n",
            "| nupdates           | 12500    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 250000   |\n",
            "| value_loss         | 0.000406 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 185      |\n",
            "| ep_reward_mean     | 185      |\n",
            "| explained_variance | -19.2    |\n",
            "| fps                | 2582     |\n",
            "| nupdates           | 12600    |\n",
            "| policy_entropy     | 0.499    |\n",
            "| total_timesteps    | 252000   |\n",
            "| value_loss         | 0.000382 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 193      |\n",
            "| ep_reward_mean     | 193      |\n",
            "| explained_variance | 0.64     |\n",
            "| fps                | 2583     |\n",
            "| nupdates           | 12700    |\n",
            "| policy_entropy     | 0.627    |\n",
            "| total_timesteps    | 254000   |\n",
            "| value_loss         | 0.000158 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 201      |\n",
            "| ep_reward_mean     | 201      |\n",
            "| explained_variance | 0.291    |\n",
            "| fps                | 2583     |\n",
            "| nupdates           | 12800    |\n",
            "| policy_entropy     | 0.632    |\n",
            "| total_timesteps    | 256000   |\n",
            "| value_loss         | 0.00027  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 203      |\n",
            "| ep_reward_mean     | 203      |\n",
            "| explained_variance | -1.24    |\n",
            "| fps                | 2583     |\n",
            "| nupdates           | 12900    |\n",
            "| policy_entropy     | 0.55     |\n",
            "| total_timesteps    | 258000   |\n",
            "| value_loss         | 0.000202 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 205      |\n",
            "| ep_reward_mean     | 205      |\n",
            "| explained_variance | 0.486    |\n",
            "| fps                | 2583     |\n",
            "| nupdates           | 13000    |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 260000   |\n",
            "| value_loss         | 0.000345 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 216      |\n",
            "| ep_reward_mean     | 216      |\n",
            "| explained_variance | -3.83    |\n",
            "| fps                | 2580     |\n",
            "| nupdates           | 13100    |\n",
            "| policy_entropy     | 0.511    |\n",
            "| total_timesteps    | 262000   |\n",
            "| value_loss         | 0.00011  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 220      |\n",
            "| ep_reward_mean     | 220      |\n",
            "| explained_variance | -0.21    |\n",
            "| fps                | 2571     |\n",
            "| nupdates           | 13200    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 264000   |\n",
            "| value_loss         | 0.000471 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 223      |\n",
            "| ep_reward_mean     | 223      |\n",
            "| explained_variance | 0.103    |\n",
            "| fps                | 2564     |\n",
            "| nupdates           | 13300    |\n",
            "| policy_entropy     | 0.406    |\n",
            "| total_timesteps    | 266000   |\n",
            "| value_loss         | 0.000676 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 224      |\n",
            "| ep_reward_mean     | 224      |\n",
            "| explained_variance | 0.0589   |\n",
            "| fps                | 2557     |\n",
            "| nupdates           | 13400    |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 268000   |\n",
            "| value_loss         | 0.000324 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 224      |\n",
            "| ep_reward_mean     | 224      |\n",
            "| explained_variance | 0.0887   |\n",
            "| fps                | 2551     |\n",
            "| nupdates           | 13500    |\n",
            "| policy_entropy     | 0.533    |\n",
            "| total_timesteps    | 270000   |\n",
            "| value_loss         | 0.000583 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 218      |\n",
            "| ep_reward_mean     | 218      |\n",
            "| explained_variance | 0.218    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 13600    |\n",
            "| policy_entropy     | 0.48     |\n",
            "| total_timesteps    | 272000   |\n",
            "| value_loss         | 0.000462 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 218      |\n",
            "| ep_reward_mean     | 218      |\n",
            "| explained_variance | 0.933    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 13700    |\n",
            "| policy_entropy     | 0.545    |\n",
            "| total_timesteps    | 274000   |\n",
            "| value_loss         | 3.19e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 220      |\n",
            "| ep_reward_mean     | 220      |\n",
            "| explained_variance | 0.905    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 13800    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 276000   |\n",
            "| value_loss         | 8.41e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 226      |\n",
            "| ep_reward_mean     | 226      |\n",
            "| explained_variance | 0.956    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 13900    |\n",
            "| policy_entropy     | 0.576    |\n",
            "| total_timesteps    | 278000   |\n",
            "| value_loss         | 0.00016  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 227      |\n",
            "| ep_reward_mean     | 227      |\n",
            "| explained_variance | 0.735    |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 14000    |\n",
            "| policy_entropy     | 0.61     |\n",
            "| total_timesteps    | 280000   |\n",
            "| value_loss         | 0.000312 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 228      |\n",
            "| ep_reward_mean     | 228      |\n",
            "| explained_variance | 0.527    |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 14100    |\n",
            "| policy_entropy     | 0.514    |\n",
            "| total_timesteps    | 282000   |\n",
            "| value_loss         | 0.000384 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 233      |\n",
            "| ep_reward_mean     | 233      |\n",
            "| explained_variance | -0.101   |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 14200    |\n",
            "| policy_entropy     | 0.582    |\n",
            "| total_timesteps    | 284000   |\n",
            "| value_loss         | 0.000421 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 231      |\n",
            "| ep_reward_mean     | 231      |\n",
            "| explained_variance | 0.929    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 14300    |\n",
            "| policy_entropy     | 0.627    |\n",
            "| total_timesteps    | 286000   |\n",
            "| value_loss         | 0.000288 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | -0.249   |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 14400    |\n",
            "| policy_entropy     | 0.538    |\n",
            "| total_timesteps    | 288000   |\n",
            "| value_loss         | 0.000306 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.582    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 14500    |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 290000   |\n",
            "| value_loss         | 0.000157 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 235      |\n",
            "| ep_reward_mean     | 235      |\n",
            "| explained_variance | -0.107   |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 14600    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 292000   |\n",
            "| value_loss         | 7.81e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 235      |\n",
            "| ep_reward_mean     | 235      |\n",
            "| explained_variance | -0.208   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 14700    |\n",
            "| policy_entropy     | 0.566    |\n",
            "| total_timesteps    | 294000   |\n",
            "| value_loss         | 0.00035  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 234      |\n",
            "| ep_reward_mean     | 234      |\n",
            "| explained_variance | 0.911    |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 14800    |\n",
            "| policy_entropy     | 0.635    |\n",
            "| total_timesteps    | 296000   |\n",
            "| value_loss         | 0.000163 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | -25      |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 14900    |\n",
            "| policy_entropy     | 0.59     |\n",
            "| total_timesteps    | 298000   |\n",
            "| value_loss         | 0.0031   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 238      |\n",
            "| ep_reward_mean     | 238      |\n",
            "| explained_variance | 0.392    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 15000    |\n",
            "| policy_entropy     | 0.581    |\n",
            "| total_timesteps    | 300000   |\n",
            "| value_loss         | 9.81e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.612    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 15100    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 302000   |\n",
            "| value_loss         | 0.000216 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 240      |\n",
            "| ep_reward_mean     | 240      |\n",
            "| explained_variance | 0.347    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 15200    |\n",
            "| policy_entropy     | 0.579    |\n",
            "| total_timesteps    | 304000   |\n",
            "| value_loss         | 9.32e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 240      |\n",
            "| ep_reward_mean     | 240      |\n",
            "| explained_variance | 0.0106   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 15300    |\n",
            "| policy_entropy     | 0.616    |\n",
            "| total_timesteps    | 306000   |\n",
            "| value_loss         | 3.38e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 239      |\n",
            "| ep_reward_mean     | 239      |\n",
            "| explained_variance | 0.713    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 15400    |\n",
            "| policy_entropy     | 0.547    |\n",
            "| total_timesteps    | 308000   |\n",
            "| value_loss         | 0.000149 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 229      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | -4.45    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 15500    |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 310000   |\n",
            "| value_loss         | 0.00034  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 229      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | -0.0822  |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 15600    |\n",
            "| policy_entropy     | 0.496    |\n",
            "| total_timesteps    | 312000   |\n",
            "| value_loss         | 0.000192 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 228      |\n",
            "| ep_reward_mean     | 228      |\n",
            "| explained_variance | 0.784    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 15700    |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 314000   |\n",
            "| value_loss         | 0.000213 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 228      |\n",
            "| ep_reward_mean     | 228      |\n",
            "| explained_variance | 0.352    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 15800    |\n",
            "| policy_entropy     | 0.539    |\n",
            "| total_timesteps    | 316000   |\n",
            "| value_loss         | 0.000188 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 222      |\n",
            "| ep_reward_mean     | 222      |\n",
            "| explained_variance | 0.00143  |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 15900    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 318000   |\n",
            "| value_loss         | 965      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 221      |\n",
            "| ep_reward_mean     | 221      |\n",
            "| explained_variance | -0.322   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 16000    |\n",
            "| policy_entropy     | 0.432    |\n",
            "| total_timesteps    | 320000   |\n",
            "| value_loss         | 0.000238 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 221      |\n",
            "| ep_reward_mean     | 221      |\n",
            "| explained_variance | -1.76    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 16100    |\n",
            "| policy_entropy     | 0.55     |\n",
            "| total_timesteps    | 322000   |\n",
            "| value_loss         | 0.000385 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 229      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | 0.832    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 16200    |\n",
            "| policy_entropy     | 0.623    |\n",
            "| total_timesteps    | 324000   |\n",
            "| value_loss         | 6.72e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 229      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | 0.396    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 16300    |\n",
            "| policy_entropy     | 0.535    |\n",
            "| total_timesteps    | 326000   |\n",
            "| value_loss         | 0.000347 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 232      |\n",
            "| ep_reward_mean     | 232      |\n",
            "| explained_variance | -6.46    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 16400    |\n",
            "| policy_entropy     | 0.368    |\n",
            "| total_timesteps    | 328000   |\n",
            "| value_loss         | 0.000331 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 229      |\n",
            "| ep_reward_mean     | 229      |\n",
            "| explained_variance | 0.894    |\n",
            "| fps                | 2527     |\n",
            "| nupdates           | 16500    |\n",
            "| policy_entropy     | 0.57     |\n",
            "| total_timesteps    | 330000   |\n",
            "| value_loss         | 0.000356 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 232      |\n",
            "| ep_reward_mean     | 232      |\n",
            "| explained_variance | -0.348   |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 16600    |\n",
            "| policy_entropy     | 0.534    |\n",
            "| total_timesteps    | 332000   |\n",
            "| value_loss         | 8.56e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 232      |\n",
            "| ep_reward_mean     | 232      |\n",
            "| explained_variance | 0.236    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 16700    |\n",
            "| policy_entropy     | 0.636    |\n",
            "| total_timesteps    | 334000   |\n",
            "| value_loss         | 4.51e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.0119   |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 16800    |\n",
            "| policy_entropy     | 0.466    |\n",
            "| total_timesteps    | 336000   |\n",
            "| value_loss         | 0.000118 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 235      |\n",
            "| ep_reward_mean     | 235      |\n",
            "| explained_variance | 0.835    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 16900    |\n",
            "| policy_entropy     | 0.421    |\n",
            "| total_timesteps    | 338000   |\n",
            "| value_loss         | 0.000262 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.63     |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 17000    |\n",
            "| policy_entropy     | 0.599    |\n",
            "| total_timesteps    | 340000   |\n",
            "| value_loss         | 0.000108 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 241      |\n",
            "| ep_reward_mean     | 241      |\n",
            "| explained_variance | -2.1     |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 17100    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 342000   |\n",
            "| value_loss         | 0.000207 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 241      |\n",
            "| ep_reward_mean     | 241      |\n",
            "| explained_variance | -3.3     |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 17200    |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 344000   |\n",
            "| value_loss         | 0.000171 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 241      |\n",
            "| ep_reward_mean     | 241      |\n",
            "| explained_variance | 0.486    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 17300    |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 346000   |\n",
            "| value_loss         | 0.000375 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | -0.272   |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 17400    |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 348000   |\n",
            "| value_loss         | 9.19e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 242      |\n",
            "| ep_reward_mean     | 242      |\n",
            "| explained_variance | -0.716   |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 17500    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 350000   |\n",
            "| value_loss         | 5.23e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 240      |\n",
            "| ep_reward_mean     | 240      |\n",
            "| explained_variance | 0.213    |\n",
            "| fps                | 2532     |\n",
            "| nupdates           | 17600    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 352000   |\n",
            "| value_loss         | 0.000245 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 235      |\n",
            "| ep_reward_mean     | 235      |\n",
            "| explained_variance | -0.361   |\n",
            "| fps                | 2532     |\n",
            "| nupdates           | 17700    |\n",
            "| policy_entropy     | 0.586    |\n",
            "| total_timesteps    | 354000   |\n",
            "| value_loss         | 0.00106  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 238      |\n",
            "| ep_reward_mean     | 238      |\n",
            "| explained_variance | -3.26    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 17800    |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 356000   |\n",
            "| value_loss         | 0.000311 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 240      |\n",
            "| ep_reward_mean     | 240      |\n",
            "| explained_variance | 0.479    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 17900    |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 358000   |\n",
            "| value_loss         | 0.000186 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.887    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 18000    |\n",
            "| policy_entropy     | 0.546    |\n",
            "| total_timesteps    | 360000   |\n",
            "| value_loss         | 0.000477 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.867    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 18100    |\n",
            "| policy_entropy     | 0.61     |\n",
            "| total_timesteps    | 362000   |\n",
            "| value_loss         | 0.000396 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 242      |\n",
            "| ep_reward_mean     | 242      |\n",
            "| explained_variance | 0.326    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 18200    |\n",
            "| policy_entropy     | 0.595    |\n",
            "| total_timesteps    | 364000   |\n",
            "| value_loss         | 0.000395 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 242      |\n",
            "| ep_reward_mean     | 242      |\n",
            "| explained_variance | 0.63     |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 18300    |\n",
            "| policy_entropy     | 0.573    |\n",
            "| total_timesteps    | 366000   |\n",
            "| value_loss         | 0.000315 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 241      |\n",
            "| ep_reward_mean     | 241      |\n",
            "| explained_variance | -0.595   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 18400    |\n",
            "| policy_entropy     | 0.537    |\n",
            "| total_timesteps    | 368000   |\n",
            "| value_loss         | 0.000132 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | -0.053   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 18500    |\n",
            "| policy_entropy     | 0.437    |\n",
            "| total_timesteps    | 370000   |\n",
            "| value_loss         | 0.000542 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 238      |\n",
            "| ep_reward_mean     | 238      |\n",
            "| explained_variance | 0.184    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 18600    |\n",
            "| policy_entropy     | 0.511    |\n",
            "| total_timesteps    | 372000   |\n",
            "| value_loss         | 0.000162 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 234      |\n",
            "| ep_reward_mean     | 234      |\n",
            "| explained_variance | -0.333   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 18700    |\n",
            "| policy_entropy     | 0.61     |\n",
            "| total_timesteps    | 374000   |\n",
            "| value_loss         | 4.25e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 237      |\n",
            "| ep_reward_mean     | 237      |\n",
            "| explained_variance | 0.827    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 18800    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 376000   |\n",
            "| value_loss         | 0.000108 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | 0.0927   |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 18900    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 378000   |\n",
            "| value_loss         | 0.000219 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | 0.821    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 19000    |\n",
            "| policy_entropy     | 0.568    |\n",
            "| total_timesteps    | 380000   |\n",
            "| value_loss         | 0.000163 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -1.08    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 19100    |\n",
            "| policy_entropy     | 0.469    |\n",
            "| total_timesteps    | 382000   |\n",
            "| value_loss         | 0.000247 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.294    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 19200    |\n",
            "| policy_entropy     | 0.529    |\n",
            "| total_timesteps    | 384000   |\n",
            "| value_loss         | 0.000223 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.7      |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 19300    |\n",
            "| policy_entropy     | 0.462    |\n",
            "| total_timesteps    | 386000   |\n",
            "| value_loss         | 0.000453 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.624    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 19400    |\n",
            "| policy_entropy     | 0.628    |\n",
            "| total_timesteps    | 388000   |\n",
            "| value_loss         | 0.000144 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -0.53    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 19500    |\n",
            "| policy_entropy     | 0.588    |\n",
            "| total_timesteps    | 390000   |\n",
            "| value_loss         | 0.000111 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.83     |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 19600    |\n",
            "| policy_entropy     | 0.525    |\n",
            "| total_timesteps    | 392000   |\n",
            "| value_loss         | 0.000337 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.857    |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 19700    |\n",
            "| policy_entropy     | 0.524    |\n",
            "| total_timesteps    | 394000   |\n",
            "| value_loss         | 0.000296 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | 0.113    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 19800    |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 396000   |\n",
            "| value_loss         | 9.91e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.586    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 19900    |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 398000   |\n",
            "| value_loss         | 0.000101 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.729    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 20000    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 400000   |\n",
            "| value_loss         | 3.42e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.146    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 20100    |\n",
            "| policy_entropy     | 0.49     |\n",
            "| total_timesteps    | 402000   |\n",
            "| value_loss         | 0.000208 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.153    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 20200    |\n",
            "| policy_entropy     | 0.601    |\n",
            "| total_timesteps    | 404000   |\n",
            "| value_loss         | 0.000168 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.0871  |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 20300    |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 406000   |\n",
            "| value_loss         | 0.000439 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.52     |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 20400    |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 408000   |\n",
            "| value_loss         | 0.000209 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -1.56    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 20500    |\n",
            "| policy_entropy     | 0.547    |\n",
            "| total_timesteps    | 410000   |\n",
            "| value_loss         | 0.000162 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.53     |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 20600    |\n",
            "| policy_entropy     | 0.51     |\n",
            "| total_timesteps    | 412000   |\n",
            "| value_loss         | 8.55e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.437    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 20700    |\n",
            "| policy_entropy     | 0.617    |\n",
            "| total_timesteps    | 414000   |\n",
            "| value_loss         | 0.000214 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.753    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 20800    |\n",
            "| policy_entropy     | 0.544    |\n",
            "| total_timesteps    | 416000   |\n",
            "| value_loss         | 0.00024  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.0953   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 20900    |\n",
            "| policy_entropy     | 0.597    |\n",
            "| total_timesteps    | 418000   |\n",
            "| value_loss         | 0.000264 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.0976  |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 21000    |\n",
            "| policy_entropy     | 0.509    |\n",
            "| total_timesteps    | 420000   |\n",
            "| value_loss         | 0.00075  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.893    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 21100    |\n",
            "| policy_entropy     | 0.606    |\n",
            "| total_timesteps    | 422000   |\n",
            "| value_loss         | 0.000359 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.55     |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 21200    |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 424000   |\n",
            "| value_loss         | 6.43e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.412    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 21300    |\n",
            "| policy_entropy     | 0.568    |\n",
            "| total_timesteps    | 426000   |\n",
            "| value_loss         | 0.000311 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.739    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 21400    |\n",
            "| policy_entropy     | 0.585    |\n",
            "| total_timesteps    | 428000   |\n",
            "| value_loss         | 5.43e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.691   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 21500    |\n",
            "| policy_entropy     | 0.488    |\n",
            "| total_timesteps    | 430000   |\n",
            "| value_loss         | 0.000508 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.683    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 21600    |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 432000   |\n",
            "| value_loss         | 4.65e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.0811   |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 21700    |\n",
            "| policy_entropy     | 0.548    |\n",
            "| total_timesteps    | 434000   |\n",
            "| value_loss         | 0.000115 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | -4.6     |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 21800    |\n",
            "| policy_entropy     | 0.595    |\n",
            "| total_timesteps    | 436000   |\n",
            "| value_loss         | 0.000101 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -1.01    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 21900    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 438000   |\n",
            "| value_loss         | 0.000112 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.725    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 22000    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 440000   |\n",
            "| value_loss         | 0.000236 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.944   |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 22100    |\n",
            "| policy_entropy     | 0.503    |\n",
            "| total_timesteps    | 442000   |\n",
            "| value_loss         | 0.0003   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -1.08    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 22200    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 444000   |\n",
            "| value_loss         | 0.000242 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.231    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 22300    |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 446000   |\n",
            "| value_loss         | 0.000238 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -0.259   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 22400    |\n",
            "| policy_entropy     | 0.562    |\n",
            "| total_timesteps    | 448000   |\n",
            "| value_loss         | 0.000133 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.758    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 22500    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 450000   |\n",
            "| value_loss         | 4.04e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -0.423   |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 22600    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 452000   |\n",
            "| value_loss         | 0.000124 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.231    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 22700    |\n",
            "| policy_entropy     | 0.586    |\n",
            "| total_timesteps    | 454000   |\n",
            "| value_loss         | 0.000153 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.534    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 22800    |\n",
            "| policy_entropy     | 0.521    |\n",
            "| total_timesteps    | 456000   |\n",
            "| value_loss         | 0.000132 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.365    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 22900    |\n",
            "| policy_entropy     | 0.592    |\n",
            "| total_timesteps    | 458000   |\n",
            "| value_loss         | 0.000215 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.762    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23000    |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 460000   |\n",
            "| value_loss         | 7.81e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.228    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23100    |\n",
            "| policy_entropy     | 0.507    |\n",
            "| total_timesteps    | 462000   |\n",
            "| value_loss         | 6.22e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 266      |\n",
            "| ep_reward_mean     | 266      |\n",
            "| explained_variance | 0.897    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23200    |\n",
            "| policy_entropy     | 0.538    |\n",
            "| total_timesteps    | 464000   |\n",
            "| value_loss         | 4.89e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 266      |\n",
            "| ep_reward_mean     | 266      |\n",
            "| explained_variance | 0.728    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23300    |\n",
            "| policy_entropy     | 0.597    |\n",
            "| total_timesteps    | 466000   |\n",
            "| value_loss         | 8.64e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -1.38    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23400    |\n",
            "| policy_entropy     | 0.499    |\n",
            "| total_timesteps    | 468000   |\n",
            "| value_loss         | 0.00019  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -0.167   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23500    |\n",
            "| policy_entropy     | 0.497    |\n",
            "| total_timesteps    | 470000   |\n",
            "| value_loss         | 0.000229 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -0.452   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23600    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 472000   |\n",
            "| value_loss         | 0.000106 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.564    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 23700    |\n",
            "| policy_entropy     | 0.462    |\n",
            "| total_timesteps    | 474000   |\n",
            "| value_loss         | 0.000487 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -0.893   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23800    |\n",
            "| policy_entropy     | 0.401    |\n",
            "| total_timesteps    | 476000   |\n",
            "| value_loss         | 0.00141  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 266      |\n",
            "| ep_reward_mean     | 266      |\n",
            "| explained_variance | -2.43    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 23900    |\n",
            "| policy_entropy     | 0.508    |\n",
            "| total_timesteps    | 478000   |\n",
            "| value_loss         | 0.000223 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.0358  |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 24000    |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 480000   |\n",
            "| value_loss         | 0.000103 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.768   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 24100    |\n",
            "| policy_entropy     | 0.532    |\n",
            "| total_timesteps    | 482000   |\n",
            "| value_loss         | 0.00231  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.262    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 24200    |\n",
            "| policy_entropy     | 0.451    |\n",
            "| total_timesteps    | 484000   |\n",
            "| value_loss         | 0.000257 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -0.436   |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24300    |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 486000   |\n",
            "| value_loss         | 0.000128 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.737    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24400    |\n",
            "| policy_entropy     | 0.616    |\n",
            "| total_timesteps    | 488000   |\n",
            "| value_loss         | 3.36e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -27.8    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24500    |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 490000   |\n",
            "| value_loss         | 0.000266 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.389    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24600    |\n",
            "| policy_entropy     | 0.55     |\n",
            "| total_timesteps    | 492000   |\n",
            "| value_loss         | 0.000357 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -1.99    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24700    |\n",
            "| policy_entropy     | 0.528    |\n",
            "| total_timesteps    | 494000   |\n",
            "| value_loss         | 0.000413 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | -1.43    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24800    |\n",
            "| policy_entropy     | 0.576    |\n",
            "| total_timesteps    | 496000   |\n",
            "| value_loss         | 6.07e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.247    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 24900    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 498000   |\n",
            "| value_loss         | 5.51e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | 0.819    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 25000    |\n",
            "| policy_entropy     | 0.5      |\n",
            "| total_timesteps    | 500000   |\n",
            "| value_loss         | 0.000229 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | -2.63    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25100    |\n",
            "| policy_entropy     | 0.525    |\n",
            "| total_timesteps    | 502000   |\n",
            "| value_loss         | 0.000114 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.648    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25200    |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 504000   |\n",
            "| value_loss         | 6.87e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 274      |\n",
            "| ep_reward_mean     | 274      |\n",
            "| explained_variance | 0.549    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25300    |\n",
            "| policy_entropy     | 0.628    |\n",
            "| total_timesteps    | 506000   |\n",
            "| value_loss         | 3.45e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 274      |\n",
            "| ep_reward_mean     | 274      |\n",
            "| explained_variance | -1.31    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25400    |\n",
            "| policy_entropy     | 0.441    |\n",
            "| total_timesteps    | 508000   |\n",
            "| value_loss         | 0.000422 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 277      |\n",
            "| ep_reward_mean     | 277      |\n",
            "| explained_variance | -0.0045  |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25500    |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 510000   |\n",
            "| value_loss         | 8.21e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 275      |\n",
            "| ep_reward_mean     | 275      |\n",
            "| explained_variance | -1.7     |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25600    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 512000   |\n",
            "| value_loss         | 6.14e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | 0.000432 |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25700    |\n",
            "| policy_entropy     | 0.519    |\n",
            "| total_timesteps    | 514000   |\n",
            "| value_loss         | 1.44e+03 |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 269       |\n",
            "| ep_reward_mean     | 269       |\n",
            "| explained_variance | -0.000656 |\n",
            "| fps                | 2538      |\n",
            "| nupdates           | 25800     |\n",
            "| policy_entropy     | 0.502     |\n",
            "| total_timesteps    | 516000    |\n",
            "| value_loss         | 1.43e+03  |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | 7.83e-05 |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 25900    |\n",
            "| policy_entropy     | 0.535    |\n",
            "| total_timesteps    | 518000   |\n",
            "| value_loss         | 1.43e+03 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | 0.786    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 26000    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 520000   |\n",
            "| value_loss         | 0.000129 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | -0.225   |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 26100    |\n",
            "| policy_entropy     | 0.599    |\n",
            "| total_timesteps    | 522000   |\n",
            "| value_loss         | 0.000146 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.737    |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 26200    |\n",
            "| policy_entropy     | 0.502    |\n",
            "| total_timesteps    | 524000   |\n",
            "| value_loss         | 9.58e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.126    |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 26300    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 526000   |\n",
            "| value_loss         | 3.67e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.856    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26400    |\n",
            "| policy_entropy     | 0.535    |\n",
            "| total_timesteps    | 528000   |\n",
            "| value_loss         | 6.79e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 270      |\n",
            "| ep_reward_mean     | 270      |\n",
            "| explained_variance | 0.856    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26500    |\n",
            "| policy_entropy     | 0.613    |\n",
            "| total_timesteps    | 530000   |\n",
            "| value_loss         | 4.68e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.569    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26600    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 532000   |\n",
            "| value_loss         | 0.000233 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | -0.174   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26700    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 534000   |\n",
            "| value_loss         | 0.000271 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | 0.48     |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26800    |\n",
            "| policy_entropy     | 0.642    |\n",
            "| total_timesteps    | 536000   |\n",
            "| value_loss         | 0.000222 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 267      |\n",
            "| ep_reward_mean     | 267      |\n",
            "| explained_variance | -0.302   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 26900    |\n",
            "| policy_entropy     | 0.562    |\n",
            "| total_timesteps    | 538000   |\n",
            "| value_loss         | 0.000265 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | -2.14    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 27000    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 540000   |\n",
            "| value_loss         | 0.000628 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -1.47    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 27100    |\n",
            "| policy_entropy     | 0.528    |\n",
            "| total_timesteps    | 542000   |\n",
            "| value_loss         | 0.000368 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | -0.262   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 27200    |\n",
            "| policy_entropy     | 0.589    |\n",
            "| total_timesteps    | 544000   |\n",
            "| value_loss         | 0.000153 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | -1.19    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 27300    |\n",
            "| policy_entropy     | 0.422    |\n",
            "| total_timesteps    | 546000   |\n",
            "| value_loss         | 0.000141 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.32     |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 27400    |\n",
            "| policy_entropy     | 0.438    |\n",
            "| total_timesteps    | 548000   |\n",
            "| value_loss         | 0.000585 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.00208  |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 27500    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 550000   |\n",
            "| value_loss         | 967      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 263       |\n",
            "| ep_reward_mean     | 263       |\n",
            "| explained_variance | -0.000306 |\n",
            "| fps                | 2541      |\n",
            "| nupdates           | 27600     |\n",
            "| policy_entropy     | 0.597     |\n",
            "| total_timesteps    | 552000    |\n",
            "| value_loss         | 969       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 1.68e-05 |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 27700    |\n",
            "| policy_entropy     | 0.625    |\n",
            "| total_timesteps    | 554000   |\n",
            "| value_loss         | 969      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 266       |\n",
            "| ep_reward_mean     | 266       |\n",
            "| explained_variance | -0.000225 |\n",
            "| fps                | 2542      |\n",
            "| nupdates           | 27800     |\n",
            "| policy_entropy     | 0.598     |\n",
            "| total_timesteps    | 556000    |\n",
            "| value_loss         | 969       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 265      |\n",
            "| ep_reward_mean     | 265      |\n",
            "| explained_variance | 9.08e-05 |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 27900    |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 558000   |\n",
            "| value_loss         | 970      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | -2.29    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 28000    |\n",
            "| policy_entropy     | 0.608    |\n",
            "| total_timesteps    | 560000   |\n",
            "| value_loss         | 0.000271 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | -4.02    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 28100    |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 562000   |\n",
            "| value_loss         | 0.000254 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.43     |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 28200    |\n",
            "| policy_entropy     | 0.54     |\n",
            "| total_timesteps    | 564000   |\n",
            "| value_loss         | 0.000169 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.157    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28300    |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 566000   |\n",
            "| value_loss         | 0.000163 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | 0.399    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28400    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 568000   |\n",
            "| value_loss         | 0.00013  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | 0.807    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28500    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 570000   |\n",
            "| value_loss         | 0.000212 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 265      |\n",
            "| ep_reward_mean     | 265      |\n",
            "| explained_variance | 0.66     |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28600    |\n",
            "| policy_entropy     | 0.618    |\n",
            "| total_timesteps    | 572000   |\n",
            "| value_loss         | 0.000245 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.853    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28700    |\n",
            "| policy_entropy     | 0.645    |\n",
            "| total_timesteps    | 574000   |\n",
            "| value_loss         | 0.000137 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 256      |\n",
            "| ep_reward_mean     | 256      |\n",
            "| explained_variance | 0.117    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 28800    |\n",
            "| policy_entropy     | 0.532    |\n",
            "| total_timesteps    | 576000   |\n",
            "| value_loss         | 0.000196 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.335    |\n",
            "| fps                | 2545     |\n",
            "| nupdates           | 28900    |\n",
            "| policy_entropy     | 0.599    |\n",
            "| total_timesteps    | 578000   |\n",
            "| value_loss         | 0.000283 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | 0.682    |\n",
            "| fps                | 2545     |\n",
            "| nupdates           | 29000    |\n",
            "| policy_entropy     | 0.55     |\n",
            "| total_timesteps    | 580000   |\n",
            "| value_loss         | 0.000384 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.533    |\n",
            "| fps                | 2545     |\n",
            "| nupdates           | 29100    |\n",
            "| policy_entropy     | 0.588    |\n",
            "| total_timesteps    | 582000   |\n",
            "| value_loss         | 6.66e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.868    |\n",
            "| fps                | 2545     |\n",
            "| nupdates           | 29200    |\n",
            "| policy_entropy     | 0.587    |\n",
            "| total_timesteps    | 584000   |\n",
            "| value_loss         | 7.44e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.386    |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 29300    |\n",
            "| policy_entropy     | 0.559    |\n",
            "| total_timesteps    | 586000   |\n",
            "| value_loss         | 0.000104 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.421    |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 29400    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 588000   |\n",
            "| value_loss         | 5.7e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 247      |\n",
            "| ep_reward_mean     | 247      |\n",
            "| explained_variance | -0.152   |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 29500    |\n",
            "| policy_entropy     | 0.536    |\n",
            "| total_timesteps    | 590000   |\n",
            "| value_loss         | 0.000122 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | 0.84     |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 29600    |\n",
            "| policy_entropy     | 0.608    |\n",
            "| total_timesteps    | 592000   |\n",
            "| value_loss         | 9.59e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | -0.346   |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 29700    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 594000   |\n",
            "| value_loss         | 0.000293 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | 0.62     |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 29800    |\n",
            "| policy_entropy     | 0.584    |\n",
            "| total_timesteps    | 596000   |\n",
            "| value_loss         | 8.27e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.36     |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 29900    |\n",
            "| policy_entropy     | 0.559    |\n",
            "| total_timesteps    | 598000   |\n",
            "| value_loss         | 0.000107 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | 0.184    |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 30000    |\n",
            "| policy_entropy     | 0.582    |\n",
            "| total_timesteps    | 600000   |\n",
            "| value_loss         | 0.00142  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.44     |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 30100    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 602000   |\n",
            "| value_loss         | 0.000107 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | -2.54    |\n",
            "| fps                | 2547     |\n",
            "| nupdates           | 30200    |\n",
            "| policy_entropy     | 0.598    |\n",
            "| total_timesteps    | 604000   |\n",
            "| value_loss         | 3.86e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -0.541   |\n",
            "| fps                | 2546     |\n",
            "| nupdates           | 30300    |\n",
            "| policy_entropy     | 0.481    |\n",
            "| total_timesteps    | 606000   |\n",
            "| value_loss         | 0.000419 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | 0.312    |\n",
            "| fps                | 2544     |\n",
            "| nupdates           | 30400    |\n",
            "| policy_entropy     | 0.592    |\n",
            "| total_timesteps    | 608000   |\n",
            "| value_loss         | 0.000223 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.606    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 30500    |\n",
            "| policy_entropy     | 0.613    |\n",
            "| total_timesteps    | 610000   |\n",
            "| value_loss         | 1.6e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.718    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 30600    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 612000   |\n",
            "| value_loss         | 7.06e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | -0.457   |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 30700    |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 614000   |\n",
            "| value_loss         | 4.86e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | -0.424   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 30800    |\n",
            "| policy_entropy     | 0.604    |\n",
            "| total_timesteps    | 616000   |\n",
            "| value_loss         | 8.3e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | -0.563   |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 30900    |\n",
            "| policy_entropy     | 0.614    |\n",
            "| total_timesteps    | 618000   |\n",
            "| value_loss         | 2.42e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.798    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31000    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 620000   |\n",
            "| value_loss         | 9.53e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 242      |\n",
            "| ep_reward_mean     | 242      |\n",
            "| explained_variance | -0.709   |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31100    |\n",
            "| policy_entropy     | 0.422    |\n",
            "| total_timesteps    | 622000   |\n",
            "| value_loss         | 0.000178 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.221    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31200    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 624000   |\n",
            "| value_loss         | 0.000245 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | 0.821    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31300    |\n",
            "| policy_entropy     | 0.537    |\n",
            "| total_timesteps    | 626000   |\n",
            "| value_loss         | 0.000248 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 244      |\n",
            "| ep_reward_mean     | 244      |\n",
            "| explained_variance | 0.853    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31400    |\n",
            "| policy_entropy     | 0.625    |\n",
            "| total_timesteps    | 628000   |\n",
            "| value_loss         | 4.75e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.427    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31500    |\n",
            "| policy_entropy     | 0.491    |\n",
            "| total_timesteps    | 630000   |\n",
            "| value_loss         | 0.000164 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | -2.89    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31600    |\n",
            "| policy_entropy     | 0.458    |\n",
            "| total_timesteps    | 632000   |\n",
            "| value_loss         | 0.000298 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 243      |\n",
            "| ep_reward_mean     | 243      |\n",
            "| explained_variance | 0.596    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31700    |\n",
            "| policy_entropy     | 0.625    |\n",
            "| total_timesteps    | 634000   |\n",
            "| value_loss         | 0.000126 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -1.26    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31800    |\n",
            "| policy_entropy     | 0.602    |\n",
            "| total_timesteps    | 636000   |\n",
            "| value_loss         | 0.000242 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | -1.04    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 31900    |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 638000   |\n",
            "| value_loss         | 0.000278 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 247      |\n",
            "| ep_reward_mean     | 247      |\n",
            "| explained_variance | -1.22    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32000    |\n",
            "| policy_entropy     | 0.59     |\n",
            "| total_timesteps    | 640000   |\n",
            "| value_loss         | 6.84e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | 0.329    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32100    |\n",
            "| policy_entropy     | 0.61     |\n",
            "| total_timesteps    | 642000   |\n",
            "| value_loss         | 0.00042  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | -2.18    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32200    |\n",
            "| policy_entropy     | 0.479    |\n",
            "| total_timesteps    | 644000   |\n",
            "| value_loss         | 0.000512 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | -0.0984  |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32300    |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 646000   |\n",
            "| value_loss         | 0.000132 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | 0.196    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32400    |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 648000   |\n",
            "| value_loss         | 9.79e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | 0.383    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32500    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 650000   |\n",
            "| value_loss         | 0.00104  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -0.4     |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32600    |\n",
            "| policy_entropy     | 0.643    |\n",
            "| total_timesteps    | 652000   |\n",
            "| value_loss         | 2.74e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | -0.0788  |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32700    |\n",
            "| policy_entropy     | 0.515    |\n",
            "| total_timesteps    | 654000   |\n",
            "| value_loss         | 0.000107 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | 0.00871  |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32800    |\n",
            "| policy_entropy     | 0.609    |\n",
            "| total_timesteps    | 656000   |\n",
            "| value_loss         | 0.000105 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | -0.236   |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 32900    |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 658000   |\n",
            "| value_loss         | 0.000171 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.899    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33000    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 660000   |\n",
            "| value_loss         | 9.04e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.919    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33100    |\n",
            "| policy_entropy     | 0.624    |\n",
            "| total_timesteps    | 662000   |\n",
            "| value_loss         | 5.85e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.521    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33200    |\n",
            "| policy_entropy     | 0.519    |\n",
            "| total_timesteps    | 664000   |\n",
            "| value_loss         | 0.000358 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.516    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33300    |\n",
            "| policy_entropy     | 0.594    |\n",
            "| total_timesteps    | 666000   |\n",
            "| value_loss         | 7.67e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | -2.64    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33400    |\n",
            "| policy_entropy     | 0.549    |\n",
            "| total_timesteps    | 668000   |\n",
            "| value_loss         | 0.000268 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 246      |\n",
            "| ep_reward_mean     | 246      |\n",
            "| explained_variance | -6.25    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33500    |\n",
            "| policy_entropy     | 0.539    |\n",
            "| total_timesteps    | 670000   |\n",
            "| value_loss         | 0.000461 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.517    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33600    |\n",
            "| policy_entropy     | 0.57     |\n",
            "| total_timesteps    | 672000   |\n",
            "| value_loss         | 0.00012  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | -0.136   |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 33700    |\n",
            "| policy_entropy     | 0.521    |\n",
            "| total_timesteps    | 674000   |\n",
            "| value_loss         | 0.000727 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | -0.611   |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 33800    |\n",
            "| policy_entropy     | 0.587    |\n",
            "| total_timesteps    | 676000   |\n",
            "| value_loss         | 0.000429 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 247      |\n",
            "| ep_reward_mean     | 247      |\n",
            "| explained_variance | 0.575    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 33900    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 678000   |\n",
            "| value_loss         | 0.000412 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | 0.387    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 34000    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 680000   |\n",
            "| value_loss         | 0.000278 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.319    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 34100    |\n",
            "| policy_entropy     | 0.579    |\n",
            "| total_timesteps    | 682000   |\n",
            "| value_loss         | 0.000164 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | -0.655   |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 34200    |\n",
            "| policy_entropy     | 0.617    |\n",
            "| total_timesteps    | 684000   |\n",
            "| value_loss         | 0.000255 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.907    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 34300    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 686000   |\n",
            "| value_loss         | 0.000219 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.0338  |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 34400    |\n",
            "| policy_entropy     | 0.502    |\n",
            "| total_timesteps    | 688000   |\n",
            "| value_loss         | 0.000571 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | 0.00433  |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 34500    |\n",
            "| policy_entropy     | 0.6      |\n",
            "| total_timesteps    | 690000   |\n",
            "| value_loss         | 9.87e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.094   |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 34600    |\n",
            "| policy_entropy     | 0.538    |\n",
            "| total_timesteps    | 692000   |\n",
            "| value_loss         | 0.00015  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.877    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 34700    |\n",
            "| policy_entropy     | 0.613    |\n",
            "| total_timesteps    | 694000   |\n",
            "| value_loss         | 0.000105 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.284    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 34800    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 696000   |\n",
            "| value_loss         | 0.000409 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.176    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 34900    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 698000   |\n",
            "| value_loss         | 9.25e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 256      |\n",
            "| ep_reward_mean     | 256      |\n",
            "| explained_variance | -4.55    |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 35000    |\n",
            "| policy_entropy     | 0.513    |\n",
            "| total_timesteps    | 700000   |\n",
            "| value_loss         | 0.00124  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | 0.809    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35100    |\n",
            "| policy_entropy     | 0.495    |\n",
            "| total_timesteps    | 702000   |\n",
            "| value_loss         | 0.000401 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | -1.07    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35200    |\n",
            "| policy_entropy     | 0.587    |\n",
            "| total_timesteps    | 704000   |\n",
            "| value_loss         | 0.000308 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.169    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35300    |\n",
            "| policy_entropy     | 0.478    |\n",
            "| total_timesteps    | 706000   |\n",
            "| value_loss         | 0.000369 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -0.573   |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35400    |\n",
            "| policy_entropy     | 0.552    |\n",
            "| total_timesteps    | 708000   |\n",
            "| value_loss         | 0.000347 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.875    |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35500    |\n",
            "| policy_entropy     | 0.597    |\n",
            "| total_timesteps    | 710000   |\n",
            "| value_loss         | 9.18e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.89     |\n",
            "| fps                | 2536     |\n",
            "| nupdates           | 35600    |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 712000   |\n",
            "| value_loss         | 0.000298 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | -0.682   |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 35700    |\n",
            "| policy_entropy     | 0.535    |\n",
            "| total_timesteps    | 714000   |\n",
            "| value_loss         | 0.000155 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.908    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 35800    |\n",
            "| policy_entropy     | 0.537    |\n",
            "| total_timesteps    | 716000   |\n",
            "| value_loss         | 0.000264 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.787    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 35900    |\n",
            "| policy_entropy     | 0.568    |\n",
            "| total_timesteps    | 718000   |\n",
            "| value_loss         | 0.000224 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | 0.807    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 36000    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 720000   |\n",
            "| value_loss         | 9.31e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -0.171   |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 36100    |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 722000   |\n",
            "| value_loss         | 0.00171  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -2.08    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 36200    |\n",
            "| policy_entropy     | 0.604    |\n",
            "| total_timesteps    | 724000   |\n",
            "| value_loss         | 0.000225 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.448    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 36300    |\n",
            "| policy_entropy     | 0.481    |\n",
            "| total_timesteps    | 726000   |\n",
            "| value_loss         | 0.000584 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.00136  |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 36400    |\n",
            "| policy_entropy     | 0.574    |\n",
            "| total_timesteps    | 728000   |\n",
            "| value_loss         | 0.000254 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.297    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 36500    |\n",
            "| policy_entropy     | 0.459    |\n",
            "| total_timesteps    | 730000   |\n",
            "| value_loss         | 0.000287 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | 0.66     |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 36600    |\n",
            "| policy_entropy     | 0.641    |\n",
            "| total_timesteps    | 732000   |\n",
            "| value_loss         | 5.41e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | -6.25    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 36700    |\n",
            "| policy_entropy     | 0.559    |\n",
            "| total_timesteps    | 734000   |\n",
            "| value_loss         | 0.000152 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | -0.442   |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 36800    |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 736000   |\n",
            "| value_loss         | 7.49e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | 0.612    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 36900    |\n",
            "| policy_entropy     | 0.637    |\n",
            "| total_timesteps    | 738000   |\n",
            "| value_loss         | 0.000102 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | 0.8      |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 37000    |\n",
            "| policy_entropy     | 0.527    |\n",
            "| total_timesteps    | 740000   |\n",
            "| value_loss         | 0.000312 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | -5.58    |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 37100    |\n",
            "| policy_entropy     | 0.58     |\n",
            "| total_timesteps    | 742000   |\n",
            "| value_loss         | 0.000306 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | -0.604   |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 37200    |\n",
            "| policy_entropy     | 0.553    |\n",
            "| total_timesteps    | 744000   |\n",
            "| value_loss         | 0.000254 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.226    |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 37300    |\n",
            "| policy_entropy     | 0.589    |\n",
            "| total_timesteps    | 746000   |\n",
            "| value_loss         | 0.000176 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | 0.000153 |\n",
            "| fps                | 2539     |\n",
            "| nupdates           | 37400    |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 748000   |\n",
            "| value_loss         | 488      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.00036  |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 37500    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 750000   |\n",
            "| value_loss         | 489      |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| ep_len_mean        | 251       |\n",
            "| ep_reward_mean     | 251       |\n",
            "| explained_variance | -0.000619 |\n",
            "| fps                | 2540      |\n",
            "| nupdates           | 37600     |\n",
            "| policy_entropy     | 0.561     |\n",
            "| total_timesteps    | 752000    |\n",
            "| value_loss         | 489       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | -0.57    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 37700    |\n",
            "| policy_entropy     | 0.543    |\n",
            "| total_timesteps    | 754000   |\n",
            "| value_loss         | 0.000326 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.202    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 37800    |\n",
            "| policy_entropy     | 0.625    |\n",
            "| total_timesteps    | 756000   |\n",
            "| value_loss         | 0.0014   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | 0.733    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 37900    |\n",
            "| policy_entropy     | 0.486    |\n",
            "| total_timesteps    | 758000   |\n",
            "| value_loss         | 0.000666 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.746   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38000    |\n",
            "| policy_entropy     | 0.463    |\n",
            "| total_timesteps    | 760000   |\n",
            "| value_loss         | 0.000655 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | 0.616    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 38100    |\n",
            "| policy_entropy     | 0.546    |\n",
            "| total_timesteps    | 762000   |\n",
            "| value_loss         | 0.000396 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | 0.873    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38200    |\n",
            "| policy_entropy     | 0.505    |\n",
            "| total_timesteps    | 764000   |\n",
            "| value_loss         | 0.000319 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.421    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38300    |\n",
            "| policy_entropy     | 0.646    |\n",
            "| total_timesteps    | 766000   |\n",
            "| value_loss         | 5.87e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.0825   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38400    |\n",
            "| policy_entropy     | 0.626    |\n",
            "| total_timesteps    | 768000   |\n",
            "| value_loss         | 4.12e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | 0.516    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38500    |\n",
            "| policy_entropy     | 0.601    |\n",
            "| total_timesteps    | 770000   |\n",
            "| value_loss         | 0.000144 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | 0.929    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38600    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 772000   |\n",
            "| value_loss         | 0.00013  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | -1.14    |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38700    |\n",
            "| policy_entropy     | 0.549    |\n",
            "| total_timesteps    | 774000   |\n",
            "| value_loss         | 0.00011  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | -0.347   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 38800    |\n",
            "| policy_entropy     | 0.518    |\n",
            "| total_timesteps    | 776000   |\n",
            "| value_loss         | 0.000488 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | 0.423    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 38900    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 778000   |\n",
            "| value_loss         | 0.000467 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | 0.468    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39000    |\n",
            "| policy_entropy     | 0.497    |\n",
            "| total_timesteps    | 780000   |\n",
            "| value_loss         | 0.000205 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | -0.824   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39100    |\n",
            "| policy_entropy     | 0.498    |\n",
            "| total_timesteps    | 782000   |\n",
            "| value_loss         | 0.00026  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | 0.405    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39200    |\n",
            "| policy_entropy     | 0.556    |\n",
            "| total_timesteps    | 784000   |\n",
            "| value_loss         | 0.000183 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 254      |\n",
            "| ep_reward_mean     | 254      |\n",
            "| explained_variance | -3.38    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39300    |\n",
            "| policy_entropy     | 0.556    |\n",
            "| total_timesteps    | 786000   |\n",
            "| value_loss         | 0.000139 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | -1.51    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39400    |\n",
            "| policy_entropy     | 0.583    |\n",
            "| total_timesteps    | 788000   |\n",
            "| value_loss         | 7.71e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 257      |\n",
            "| ep_reward_mean     | 257      |\n",
            "| explained_variance | -8.74    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39500    |\n",
            "| policy_entropy     | 0.484    |\n",
            "| total_timesteps    | 790000   |\n",
            "| value_loss         | 0.000915 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.802    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39600    |\n",
            "| policy_entropy     | 0.551    |\n",
            "| total_timesteps    | 792000   |\n",
            "| value_loss         | 0.000238 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.883   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39700    |\n",
            "| policy_entropy     | 0.587    |\n",
            "| total_timesteps    | 794000   |\n",
            "| value_loss         | 0.000163 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -2.39    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39800    |\n",
            "| policy_entropy     | 0.608    |\n",
            "| total_timesteps    | 796000   |\n",
            "| value_loss         | 0.000403 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.152    |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 39900    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 798000   |\n",
            "| value_loss         | 0.000109 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.462   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 40000    |\n",
            "| policy_entropy     | 0.601    |\n",
            "| total_timesteps    | 800000   |\n",
            "| value_loss         | 0.000213 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.182    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40100    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 802000   |\n",
            "| value_loss         | 0.00019  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.0588   |\n",
            "| fps                | 2541     |\n",
            "| nupdates           | 40200    |\n",
            "| policy_entropy     | 0.639    |\n",
            "| total_timesteps    | 804000   |\n",
            "| value_loss         | 0.000166 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.498    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40300    |\n",
            "| policy_entropy     | 0.565    |\n",
            "| total_timesteps    | 806000   |\n",
            "| value_loss         | 0.000156 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.274    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40400    |\n",
            "| policy_entropy     | 0.598    |\n",
            "| total_timesteps    | 808000   |\n",
            "| value_loss         | 0.000153 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -5.88    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40500    |\n",
            "| policy_entropy     | 0.507    |\n",
            "| total_timesteps    | 810000   |\n",
            "| value_loss         | 0.00018  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -0.00836 |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40600    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 812000   |\n",
            "| value_loss         | 0.000116 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -2.04    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40700    |\n",
            "| policy_entropy     | 0.563    |\n",
            "| total_timesteps    | 814000   |\n",
            "| value_loss         | 0.000286 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -0.0985  |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40800    |\n",
            "| policy_entropy     | 0.507    |\n",
            "| total_timesteps    | 816000   |\n",
            "| value_loss         | 0.000274 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -1.31    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 40900    |\n",
            "| policy_entropy     | 0.547    |\n",
            "| total_timesteps    | 818000   |\n",
            "| value_loss         | 0.000194 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.669   |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 41000    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 820000   |\n",
            "| value_loss         | 0.000161 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.85     |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41100    |\n",
            "| policy_entropy     | 0.51     |\n",
            "| total_timesteps    | 822000   |\n",
            "| value_loss         | 8.92e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.6      |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41200    |\n",
            "| policy_entropy     | 0.527    |\n",
            "| total_timesteps    | 824000   |\n",
            "| value_loss         | 0.000225 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.697    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41300    |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 826000   |\n",
            "| value_loss         | 7.8e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.169    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41400    |\n",
            "| policy_entropy     | 0.574    |\n",
            "| total_timesteps    | 828000   |\n",
            "| value_loss         | 0.000183 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.505    |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41500    |\n",
            "| policy_entropy     | 0.579    |\n",
            "| total_timesteps    | 830000   |\n",
            "| value_loss         | 0.000152 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.2      |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41600    |\n",
            "| policy_entropy     | 0.62     |\n",
            "| total_timesteps    | 832000   |\n",
            "| value_loss         | 7.17e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | 0.34     |\n",
            "| fps                | 2543     |\n",
            "| nupdates           | 41700    |\n",
            "| policy_entropy     | 0.617    |\n",
            "| total_timesteps    | 834000   |\n",
            "| value_loss         | 0.000208 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 253      |\n",
            "| ep_reward_mean     | 253      |\n",
            "| explained_variance | 0.414    |\n",
            "| fps                | 2542     |\n",
            "| nupdates           | 41800    |\n",
            "| policy_entropy     | 0.624    |\n",
            "| total_timesteps    | 836000   |\n",
            "| value_loss         | 0.000173 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 256      |\n",
            "| ep_reward_mean     | 256      |\n",
            "| explained_variance | -0.301   |\n",
            "| fps                | 2540     |\n",
            "| nupdates           | 41900    |\n",
            "| policy_entropy     | 0.626    |\n",
            "| total_timesteps    | 838000   |\n",
            "| value_loss         | 0.000164 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.0928   |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 42000    |\n",
            "| policy_entropy     | 0.584    |\n",
            "| total_timesteps    | 840000   |\n",
            "| value_loss         | 0.000404 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.181    |\n",
            "| fps                | 2538     |\n",
            "| nupdates           | 42100    |\n",
            "| policy_entropy     | 0.614    |\n",
            "| total_timesteps    | 842000   |\n",
            "| value_loss         | 0.000244 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.787    |\n",
            "| fps                | 2537     |\n",
            "| nupdates           | 42200    |\n",
            "| policy_entropy     | 0.621    |\n",
            "| total_timesteps    | 844000   |\n",
            "| value_loss         | 4.64e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 259      |\n",
            "| ep_reward_mean     | 259      |\n",
            "| explained_variance | -0.0643  |\n",
            "| fps                | 2535     |\n",
            "| nupdates           | 42300    |\n",
            "| policy_entropy     | 0.598    |\n",
            "| total_timesteps    | 846000   |\n",
            "| value_loss         | 8.77e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.714    |\n",
            "| fps                | 2534     |\n",
            "| nupdates           | 42400    |\n",
            "| policy_entropy     | 0.558    |\n",
            "| total_timesteps    | 848000   |\n",
            "| value_loss         | 0.00015  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -1.67    |\n",
            "| fps                | 2533     |\n",
            "| nupdates           | 42500    |\n",
            "| policy_entropy     | 0.569    |\n",
            "| total_timesteps    | 850000   |\n",
            "| value_loss         | 3.28e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.952   |\n",
            "| fps                | 2532     |\n",
            "| nupdates           | 42600    |\n",
            "| policy_entropy     | 0.614    |\n",
            "| total_timesteps    | 852000   |\n",
            "| value_loss         | 2e-05    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | 0.181    |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 42700    |\n",
            "| policy_entropy     | 0.588    |\n",
            "| total_timesteps    | 854000   |\n",
            "| value_loss         | 2.88e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.0764  |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 42800    |\n",
            "| policy_entropy     | 0.54     |\n",
            "| total_timesteps    | 856000   |\n",
            "| value_loss         | 6.63e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.501    |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 42900    |\n",
            "| policy_entropy     | 0.528    |\n",
            "| total_timesteps    | 858000   |\n",
            "| value_loss         | 0.000379 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.531    |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 43000    |\n",
            "| policy_entropy     | 0.609    |\n",
            "| total_timesteps    | 860000   |\n",
            "| value_loss         | 0.000638 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 266      |\n",
            "| ep_reward_mean     | 266      |\n",
            "| explained_variance | 0.514    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 43100    |\n",
            "| policy_entropy     | 0.527    |\n",
            "| total_timesteps    | 862000   |\n",
            "| value_loss         | 0.000138 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -8.65    |\n",
            "| fps                | 2527     |\n",
            "| nupdates           | 43200    |\n",
            "| policy_entropy     | 0.4      |\n",
            "| total_timesteps    | 864000   |\n",
            "| value_loss         | 0.000293 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.858    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 43300    |\n",
            "| policy_entropy     | 0.541    |\n",
            "| total_timesteps    | 866000   |\n",
            "| value_loss         | 5.31e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | 0.728    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 43400    |\n",
            "| policy_entropy     | 0.496    |\n",
            "| total_timesteps    | 868000   |\n",
            "| value_loss         | 0.000166 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.615    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 43500    |\n",
            "| policy_entropy     | 0.633    |\n",
            "| total_timesteps    | 870000   |\n",
            "| value_loss         | 5.69e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.089   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 43600    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 872000   |\n",
            "| value_loss         | 0.000226 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.654    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 43700    |\n",
            "| policy_entropy     | 0.528    |\n",
            "| total_timesteps    | 874000   |\n",
            "| value_loss         | 3.75e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | -1.14    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 43800    |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 876000   |\n",
            "| value_loss         | 0.00019  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 270      |\n",
            "| ep_reward_mean     | 270      |\n",
            "| explained_variance | 0.48     |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 43900    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 878000   |\n",
            "| value_loss         | 0.000575 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | 0.48     |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 44000    |\n",
            "| policy_entropy     | 0.565    |\n",
            "| total_timesteps    | 880000   |\n",
            "| value_loss         | 0.000178 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | -0.217   |\n",
            "| fps                | 2519     |\n",
            "| nupdates           | 44100    |\n",
            "| policy_entropy     | 0.534    |\n",
            "| total_timesteps    | 882000   |\n",
            "| value_loss         | 0.000324 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 274      |\n",
            "| ep_reward_mean     | 274      |\n",
            "| explained_variance | 0.504    |\n",
            "| fps                | 2518     |\n",
            "| nupdates           | 44200    |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 884000   |\n",
            "| value_loss         | 0.00013  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 274      |\n",
            "| ep_reward_mean     | 274      |\n",
            "| explained_variance | -0.119   |\n",
            "| fps                | 2518     |\n",
            "| nupdates           | 44300    |\n",
            "| policy_entropy     | 0.608    |\n",
            "| total_timesteps    | 886000   |\n",
            "| value_loss         | 8.85e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | -0.537   |\n",
            "| fps                | 2518     |\n",
            "| nupdates           | 44400    |\n",
            "| policy_entropy     | 0.567    |\n",
            "| total_timesteps    | 888000   |\n",
            "| value_loss         | 8.16e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.918    |\n",
            "| fps                | 2518     |\n",
            "| nupdates           | 44500    |\n",
            "| policy_entropy     | 0.584    |\n",
            "| total_timesteps    | 890000   |\n",
            "| value_loss         | 3.3e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.245    |\n",
            "| fps                | 2519     |\n",
            "| nupdates           | 44600    |\n",
            "| policy_entropy     | 0.481    |\n",
            "| total_timesteps    | 892000   |\n",
            "| value_loss         | 0.000528 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | 0.231    |\n",
            "| fps                | 2519     |\n",
            "| nupdates           | 44700    |\n",
            "| policy_entropy     | 0.532    |\n",
            "| total_timesteps    | 894000   |\n",
            "| value_loss         | 3.38e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | 0.967    |\n",
            "| fps                | 2519     |\n",
            "| nupdates           | 44800    |\n",
            "| policy_entropy     | 0.605    |\n",
            "| total_timesteps    | 896000   |\n",
            "| value_loss         | 2.09e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 271      |\n",
            "| ep_reward_mean     | 271      |\n",
            "| explained_variance | -0.0732  |\n",
            "| fps                | 2519     |\n",
            "| nupdates           | 44900    |\n",
            "| policy_entropy     | 0.418    |\n",
            "| total_timesteps    | 898000   |\n",
            "| value_loss         | 9.92e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 265      |\n",
            "| ep_reward_mean     | 265      |\n",
            "| explained_variance | 0.14     |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 45000    |\n",
            "| policy_entropy     | 0.629    |\n",
            "| total_timesteps    | 900000   |\n",
            "| value_loss         | 8.04e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 265      |\n",
            "| ep_reward_mean     | 265      |\n",
            "| explained_variance | -1.45    |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 45100    |\n",
            "| policy_entropy     | 0.559    |\n",
            "| total_timesteps    | 902000   |\n",
            "| value_loss         | 0.000424 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.248   |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 45200    |\n",
            "| policy_entropy     | 0.632    |\n",
            "| total_timesteps    | 904000   |\n",
            "| value_loss         | 0.000176 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 264      |\n",
            "| ep_reward_mean     | 264      |\n",
            "| explained_variance | 0.835    |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 45300    |\n",
            "| policy_entropy     | 0.585    |\n",
            "| total_timesteps    | 906000   |\n",
            "| value_loss         | 8.24e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 267      |\n",
            "| ep_reward_mean     | 267      |\n",
            "| explained_variance | -0.00715 |\n",
            "| fps                | 2520     |\n",
            "| nupdates           | 45400    |\n",
            "| policy_entropy     | 0.544    |\n",
            "| total_timesteps    | 908000   |\n",
            "| value_loss         | 0.000416 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 265      |\n",
            "| ep_reward_mean     | 265      |\n",
            "| explained_variance | -1.05    |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 45500    |\n",
            "| policy_entropy     | 0.598    |\n",
            "| total_timesteps    | 910000   |\n",
            "| value_loss         | 0.000317 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.431    |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 45600    |\n",
            "| policy_entropy     | 0.587    |\n",
            "| total_timesteps    | 912000   |\n",
            "| value_loss         | 6.5e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 268      |\n",
            "| ep_reward_mean     | 268      |\n",
            "| explained_variance | 0.249    |\n",
            "| fps                | 2521     |\n",
            "| nupdates           | 45700    |\n",
            "| policy_entropy     | 0.566    |\n",
            "| total_timesteps    | 914000   |\n",
            "| value_loss         | 6.3e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -3.21    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 45800    |\n",
            "| policy_entropy     | 0.498    |\n",
            "| total_timesteps    | 916000   |\n",
            "| value_loss         | 0.000751 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | 0.134    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 45900    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 918000   |\n",
            "| value_loss         | 8.45e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | 0.601    |\n",
            "| fps                | 2522     |\n",
            "| nupdates           | 46000    |\n",
            "| policy_entropy     | 0.591    |\n",
            "| total_timesteps    | 920000   |\n",
            "| value_loss         | 0.000134 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | -0.96    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 46100    |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 922000   |\n",
            "| value_loss         | 0.000136 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 272      |\n",
            "| ep_reward_mean     | 272      |\n",
            "| explained_variance | 0.908    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 46200    |\n",
            "| policy_entropy     | 0.612    |\n",
            "| total_timesteps    | 924000   |\n",
            "| value_loss         | 3.76e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | 0.963    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 46300    |\n",
            "| policy_entropy     | 0.634    |\n",
            "| total_timesteps    | 926000   |\n",
            "| value_loss         | 6.51e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | -1.38    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 46400    |\n",
            "| policy_entropy     | 0.503    |\n",
            "| total_timesteps    | 928000   |\n",
            "| value_loss         | 6.1e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 273      |\n",
            "| ep_reward_mean     | 273      |\n",
            "| explained_variance | -8.74    |\n",
            "| fps                | 2523     |\n",
            "| nupdates           | 46500    |\n",
            "| policy_entropy     | 0.581    |\n",
            "| total_timesteps    | 930000   |\n",
            "| value_loss         | 8e-05    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 269      |\n",
            "| ep_reward_mean     | 269      |\n",
            "| explained_variance | -0.367   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 46600    |\n",
            "| policy_entropy     | 0.513    |\n",
            "| total_timesteps    | 932000   |\n",
            "| value_loss         | 0.0002   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | -0.134   |\n",
            "| fps                | 2524     |\n",
            "| nupdates           | 46700    |\n",
            "| policy_entropy     | 0.496    |\n",
            "| total_timesteps    | 934000   |\n",
            "| value_loss         | 0.000711 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.0014   |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 46800    |\n",
            "| policy_entropy     | 0.511    |\n",
            "| total_timesteps    | 936000   |\n",
            "| value_loss         | 487      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.000659 |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 46900    |\n",
            "| policy_entropy     | 0.609    |\n",
            "| total_timesteps    | 938000   |\n",
            "| value_loss         | 487      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.000573 |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 47000    |\n",
            "| policy_entropy     | 0.549    |\n",
            "| total_timesteps    | 940000   |\n",
            "| value_loss         | 488      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.773    |\n",
            "| fps                | 2525     |\n",
            "| nupdates           | 47100    |\n",
            "| policy_entropy     | 0.577    |\n",
            "| total_timesteps    | 942000   |\n",
            "| value_loss         | 0.000279 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.0151   |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 47200    |\n",
            "| policy_entropy     | 0.561    |\n",
            "| total_timesteps    | 944000   |\n",
            "| value_loss         | 9.01e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.212    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 47300    |\n",
            "| policy_entropy     | 0.422    |\n",
            "| total_timesteps    | 946000   |\n",
            "| value_loss         | 0.00229  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | -17.6    |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 47400    |\n",
            "| policy_entropy     | 0.574    |\n",
            "| total_timesteps    | 948000   |\n",
            "| value_loss         | 0.000154 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | -0.778   |\n",
            "| fps                | 2526     |\n",
            "| nupdates           | 47500    |\n",
            "| policy_entropy     | 0.552    |\n",
            "| total_timesteps    | 950000   |\n",
            "| value_loss         | 8.45e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | 0.889    |\n",
            "| fps                | 2527     |\n",
            "| nupdates           | 47600    |\n",
            "| policy_entropy     | 0.578    |\n",
            "| total_timesteps    | 952000   |\n",
            "| value_loss         | 8.76e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | 0.219    |\n",
            "| fps                | 2527     |\n",
            "| nupdates           | 47700    |\n",
            "| policy_entropy     | 0.56     |\n",
            "| total_timesteps    | 954000   |\n",
            "| value_loss         | 4.09e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.508    |\n",
            "| fps                | 2527     |\n",
            "| nupdates           | 47800    |\n",
            "| policy_entropy     | 0.616    |\n",
            "| total_timesteps    | 956000   |\n",
            "| value_loss         | 0.0002   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | 0.695    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 47900    |\n",
            "| policy_entropy     | 0.596    |\n",
            "| total_timesteps    | 958000   |\n",
            "| value_loss         | 6.68e-06 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 262      |\n",
            "| ep_reward_mean     | 262      |\n",
            "| explained_variance | -1.75    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 48000    |\n",
            "| policy_entropy     | 0.572    |\n",
            "| total_timesteps    | 960000   |\n",
            "| value_loss         | 9.97e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 260      |\n",
            "| ep_reward_mean     | 260      |\n",
            "| explained_variance | -6.07    |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 48100    |\n",
            "| policy_entropy     | 0.485    |\n",
            "| total_timesteps    | 962000   |\n",
            "| value_loss         | 0.000358 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | -0.519   |\n",
            "| fps                | 2528     |\n",
            "| nupdates           | 48200    |\n",
            "| policy_entropy     | 0.62     |\n",
            "| total_timesteps    | 964000   |\n",
            "| value_loss         | 3.75e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 263      |\n",
            "| ep_reward_mean     | 263      |\n",
            "| explained_variance | 0.758    |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 48300    |\n",
            "| policy_entropy     | 0.525    |\n",
            "| total_timesteps    | 966000   |\n",
            "| value_loss         | 0.000226 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 261      |\n",
            "| ep_reward_mean     | 261      |\n",
            "| explained_variance | -0.364   |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 48400    |\n",
            "| policy_entropy     | 0.555    |\n",
            "| total_timesteps    | 968000   |\n",
            "| value_loss         | 0.000117 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | -4.32    |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 48500    |\n",
            "| policy_entropy     | 0.557    |\n",
            "| total_timesteps    | 970000   |\n",
            "| value_loss         | 8.01e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 258      |\n",
            "| ep_reward_mean     | 258      |\n",
            "| explained_variance | 0.929    |\n",
            "| fps                | 2529     |\n",
            "| nupdates           | 48600    |\n",
            "| policy_entropy     | 0.617    |\n",
            "| total_timesteps    | 972000   |\n",
            "| value_loss         | 0.000464 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 255      |\n",
            "| ep_reward_mean     | 255      |\n",
            "| explained_variance | -0.0429  |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 48700    |\n",
            "| policy_entropy     | 0.564    |\n",
            "| total_timesteps    | 974000   |\n",
            "| value_loss         | 9.36e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 252      |\n",
            "| ep_reward_mean     | 252      |\n",
            "| explained_variance | -4.18    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 48800    |\n",
            "| policy_entropy     | 0.619    |\n",
            "| total_timesteps    | 976000   |\n",
            "| value_loss         | 4.85e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.559    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 48900    |\n",
            "| policy_entropy     | 0.575    |\n",
            "| total_timesteps    | 978000   |\n",
            "| value_loss         | 3.46e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.158    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 49000    |\n",
            "| policy_entropy     | 0.602    |\n",
            "| total_timesteps    | 980000   |\n",
            "| value_loss         | 6.01e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 251      |\n",
            "| ep_reward_mean     | 251      |\n",
            "| explained_variance | 0.458    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 49100    |\n",
            "| policy_entropy     | 0.603    |\n",
            "| total_timesteps    | 982000   |\n",
            "| value_loss         | 8.33e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | -0.0748  |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 49200    |\n",
            "| policy_entropy     | 0.593    |\n",
            "| total_timesteps    | 984000   |\n",
            "| value_loss         | 9.62e-05 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.38     |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 49300    |\n",
            "| policy_entropy     | 0.605    |\n",
            "| total_timesteps    | 986000   |\n",
            "| value_loss         | 7.6e-05  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.164    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 49400    |\n",
            "| policy_entropy     | 0.512    |\n",
            "| total_timesteps    | 988000   |\n",
            "| value_loss         | 0.000554 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 247      |\n",
            "| ep_reward_mean     | 247      |\n",
            "| explained_variance | -4.02    |\n",
            "| fps                | 2530     |\n",
            "| nupdates           | 49500    |\n",
            "| policy_entropy     | 0.556    |\n",
            "| total_timesteps    | 990000   |\n",
            "| value_loss         | 0.000239 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 245      |\n",
            "| ep_reward_mean     | 245      |\n",
            "| explained_variance | 0.798    |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 49600    |\n",
            "| policy_entropy     | 0.631    |\n",
            "| total_timesteps    | 992000   |\n",
            "| value_loss         | 0.000212 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 248      |\n",
            "| ep_reward_mean     | 248      |\n",
            "| explained_variance | -0.0431  |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 49700    |\n",
            "| policy_entropy     | 0.547    |\n",
            "| total_timesteps    | 994000   |\n",
            "| value_loss         | 0.000402 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | 0.953    |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 49800    |\n",
            "| policy_entropy     | 0.554    |\n",
            "| total_timesteps    | 996000   |\n",
            "| value_loss         | 0.000224 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 249      |\n",
            "| ep_reward_mean     | 249      |\n",
            "| explained_variance | -1.51    |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 49900    |\n",
            "| policy_entropy     | 0.591    |\n",
            "| total_timesteps    | 998000   |\n",
            "| value_loss         | 0.000189 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| ep_len_mean        | 250      |\n",
            "| ep_reward_mean     | 250      |\n",
            "| explained_variance | -0.221   |\n",
            "| fps                | 2531     |\n",
            "| nupdates           | 50000    |\n",
            "| policy_entropy     | 0.615    |\n",
            "| total_timesteps    | 1000000  |\n",
            "| value_loss         | 0.000105 |\n",
            "---------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.a2c.a2c.A2C at 0x7fe73aa35f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz3UtG6f-gE0"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpSMss8YbnES"
      },
      "source": [
        "def evaluate(model, env, num_episodes=10):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param model: (BaseRLModel object) the RL Agent\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    # This function will only work for a single Environment\n",
        "    # single Environment에 대해서만 작동함\n",
        "    #env = model.get_env() \n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset() # e.g. [[ 0.04632042, -0.01863058, -0.03169358,  0.00881829]])\n",
        "        while not done:\n",
        "            # _states are only useful when using LSTM policies\n",
        "            action, _states = model.predict(obs, deterministic=True) # e.g.: [0], None\n",
        "            # here, action, rewards and dones are arrays\n",
        "            # because we are using vectorized env\n",
        "            obs, reward, done, info = env.step(action) #e.g.: [[0.04, -0.24, -0.03, 0.27]], [1.0], [False], [{}]\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvsUL_Ri4hhf",
        "outputId": "f7e8babb-50b6-4d42-d86a-67cf63af2cf2"
      },
      "source": [
        "# Random Agent, before training\n",
        "from stable_baselines.common import make_vec_env\n",
        "\n",
        "eval_env = make_vec_env(CartPoleEnv_stochastic, \n",
        "                   n_envs=1, \n",
        "                   seed=1000,\n",
        "                   wrapper_class=TimeLimit, \n",
        "                   env_kwargs={'mu':0., \"sigma\":0.5}) \n",
        "mean_reward_before_train = evaluate(a2c_model, eval_env, num_episodes=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 500.0 Num episodes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLjkv86Uridt",
        "outputId": "10bb1466-5663-408e-b622-ed396e373c81"
      },
      "source": [
        "from stable_baselines.common.evaluation import evaluate_policy\n",
        "eval_env = make_vec_env(CartPoleEnv_stochastic, \n",
        "                   n_envs=1, \n",
        "                   seed=1000,\n",
        "                   wrapper_class=TimeLimit, \n",
        "                   env_kwargs={'mu':0., \"sigma\":0.5})\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, eval_env, n_eval_episodes=10)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjrq1wt-rt5"
      },
      "source": [
        "# Different Dynamics Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_qhBRPvYEda",
        "outputId": "eea2726b-c066-4858-ea71-df0f6cc65b7d"
      },
      "source": [
        "# mu=0.0으로 고정\n",
        "sigmas = [0.0, 1.0, 3.0, 5.0, 10.0]\n",
        "for sigma in sigmas :\n",
        "  eval_env = make_vec_env(CartPoleEnv_stochastic, \n",
        "                   n_envs=1, \n",
        "                   seed=1000,\n",
        "                   wrapper_class=TimeLimit, \n",
        "                   env_kwargs={'mu':0., \"sigma\":sigma})\n",
        "  \n",
        "  mean_reward, std_reward = evaluate_policy(a2c_model, eval_env, n_eval_episodes=10)\n",
        "\n",
        "  print(f\"sigma:{sigma:.1f} mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sigma:0.0 mean_reward:500.00 +/- 0.00\n",
            "sigma:1.0 mean_reward:500.00 +/- 0.00\n",
            "sigma:3.0 mean_reward:500.00 +/- 0.00\n",
            "sigma:5.0 mean_reward:500.00 +/- 0.00\n",
            "sigma:10.0 mean_reward:452.30 +/- 116.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMzIjw39-xWr"
      },
      "source": [
        "# Rendering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "We will record a video using the [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder) wrapper, you will learn about those wrapper in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: env])\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOObbeu5MMlR"
      },
      "source": [
        "### Visualize trained agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iATu7AiyMQW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bdbb5c-c5c6-4450-976b-259f47ff2503"
      },
      "source": [
        "show_env = CartPoleEnv_stochastic(mu=0.0, sigma=0.0)\n",
        "show_env = gym.wrappers.TimeLimit(show_env, max_episode_steps=500)\n",
        "\n",
        "record_video(show_env, a2c_model, video_length=500, prefix='a2c-cartpole')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving video to  /content/videos/a2c-cartpole-step-0-to-step-500.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4i-fW3NojZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "3661a1c5-f59f-4486-b841-87e62c047230"
      },
      "source": [
        "show_videos('videos', prefix='a2c')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"videos/a2c-cartpole-step-0-to-step-500.mp4\" autoplay \n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Y6vRtXYDrQ"
      },
      "source": [
        "!rm /content/videos/a2c-cartpole-step-0-to-step-*"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA-e7PNsYDWT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzSGTtCATFYE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM8rPe4hTFUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}